{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "343c4746-5090-4e01-86a4-d8d485db77d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ï¸ InÃ­cio em      : 03/05/2025 09:06:34 (FlonianÃ³polis | SC)\n",
      "\n",
      "ğŸ“‹ MÃ©tricas Gerais:\n",
      "   Total originais           : 15.922\n",
      "   Duplicados removidos      : 75\n",
      "   Sem Abstract              : 0\n",
      "   Sem Affiliations          : 412\n",
      "   Sem Keywords              : 1.821\n",
      "   Total apÃ³s filtragem      : 13.614\n",
      "\n",
      "=======================================================\n",
      "â±ï¸ Tempo de execuÃ§Ã£o: 0:00:04\n",
      "ğŸ“… Finalizado em: 03/05/2025 09:06:39 (FlorianÃ³polis | SC)\n",
      "=======================================================\n",
      "â†’ Arquivo salvo em: /home/jovyan/Congresso UFSC2025/Portfolio_analitico.xlsx\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "filtrar_portfolio.py\n",
    "\n",
    "Script 1 para:\n",
    "  1) Ler CSV \"Portfolio_metadados.csv\";\n",
    "  2) Remover duplicados (baseado no tÃ­tulo normalizado);\n",
    "  3) Filtrar registros sem Abstract, Affiliations ou Author Keywords;\n",
    "  4) Reordenar colunas e salvar em Excel \"Portfolio_analitico.xlsx\";\n",
    "  5) Exibir mÃ©tricas de limpeza, data/hora e tempo de execuÃ§Ã£o.\n",
    "\n",
    "USO NO CLUSTER UFSC (JupyterLab ou SLURM):\n",
    "  â€¢ Coloque este script e o CSV na mesma pasta;\n",
    "  â€¢ No terminal do vLab:\n",
    "      module load python/3.10 pandas openpyxl\n",
    "      python filtrar_portfolio.py\n",
    "\n",
    "IMPORTANTE (CiÃªncia Aberta):\n",
    "  â€¢ Entrada: \"Portfolio_metadados.csv\" no mesmo diretÃ³rio.\n",
    "  â€¢ SaÃ­da : \"Portfolio_analitico.xlsx\" no mesmo diretÃ³rio.\n",
    "\n",
    "Autor: G.O., Renato | NEIMAC | PPGC | UFSC | Mestrado  \n",
    "Data: 01-mai-2025\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import re\n",
    "import unicodedata\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "# â”€â”€â”€ 0) marca data/hora de inÃ­cio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TZ = ZoneInfo(\"America/Sao_Paulo\")\n",
    "inicio = datetime.now(TZ)\n",
    "print(f\"â–¶ï¸ InÃ­cio em      : {inicio:%d/%m/%Y %H:%M:%S} (FlonianÃ³polis | SC)\")\n",
    "\n",
    "# 1) Instalar dependÃªncias se faltarem\n",
    "def instalar(pkg):\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except ImportError:\n",
    "        print(f\"âš™ï¸ Instalando {pkg}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "        import site; site.addsitedir(site.USER_SITE)\n",
    "\n",
    "for pkg in (\"pandas\",\"openpyxl\"):\n",
    "    instalar(pkg)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” FUNÃ‡Ã•ES AUXILIARES â€”â€”â€”â€”â€”â€”â€”\n",
    "def normalizar(texto: str) -> str:\n",
    "    if not isinstance(texto, str):\n",
    "        return \"\"\n",
    "    nfkd = unicodedata.normalize(\"NFKD\", texto)\n",
    "    s = \"\".join(c for c in nfkd if not unicodedata.combining(c)).lower()\n",
    "    s = re.sub(r\"[^a-z0-9\\s]\", \" \", s)\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "def formata_numero(n, decimals=0) -> str:\n",
    "    s = f\"{n:,.{decimals}f}\"\n",
    "    return s.replace(\",\", \"X\").replace(\".\", \",\").replace(\"X\", \".\")\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” CONFIGURAÃ‡ÃƒO DE CAMINHOS â€”â€”â€”â€”â€”â€”â€”\n",
    "try:\n",
    "    base_dir = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    base_dir = Path.cwd()\n",
    "\n",
    "csv_path    = base_dir / \"Portfolio_metadados.csv\"\n",
    "output_path = base_dir / \"Portfolio_analitico.xlsx\"\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” VERIFICAÃ‡ÃƒO DE EXISTÃŠNCIA â€”â€”â€”â€”â€”â€”â€”\n",
    "if not csv_path.exists():\n",
    "    sys.exit(f\"â›” Arquivo nÃ£o encontrado: {csv_path}\")\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” LEITURA E FILTRAGEM â€”â€”â€”â€”â€”â€”â€”\n",
    "df = pd.read_csv(csv_path)\n",
    "total_original = len(df)\n",
    "\n",
    "# 1) Duplicados (tÃ­tulo normalizado)\n",
    "df[\"Title_norm\"] = df[\"Title\"].apply(normalizar)\n",
    "mask_dup = df.duplicated(subset=\"Title_norm\", keep=\"first\")\n",
    "n_duplicados = int(mask_dup.sum())\n",
    "df = df[~mask_dup].reset_index(drop=True)\n",
    "\n",
    "# 2) Sem Abstract\n",
    "n_sem_abstract = int(df[\"Abstract\"].isna().sum())\n",
    "df = df.dropna(subset=[\"Abstract\"]).reset_index(drop=True)\n",
    "\n",
    "# 3) Sem Affiliations\n",
    "n_sem_affiliacao = int(df[\"Affiliations\"].isna().sum())\n",
    "df = df.dropna(subset=[\"Affiliations\"]).reset_index(drop=True)\n",
    "\n",
    "# 4) Sem Author Keywords\n",
    "n_sem_keywords = int(df[\"Author Keywords\"].isna().sum())\n",
    "df = df.dropna(subset=[\"Author Keywords\"]).reset_index(drop=True)\n",
    "\n",
    "total_filtrado = len(df)\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” REORDENAÃ‡ÃƒO DAS COLUNAS â€”â€”â€”â€”â€”â€”â€”\n",
    "ordem = [\n",
    "    \"Year\",\"Cited by\",\"Title\",\"Abstract\",\n",
    "    \"Affiliations\",\"Source title\",\"Author Keywords\"\n",
    "]\n",
    "df = df[ordem]\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” EXPORTAÃ‡ÃƒO PARA EXCEL â€”â€”â€”â€”â€”â€”â€”\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "# â”€â”€â”€ FIM DA CONTAGEM DO TEMPO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fim = datetime.now(TZ)\n",
    "dur = fim - inicio\n",
    "dur_str = str(dur).split(\".\")[0]\n",
    "\n",
    "# â”€â”€â”€ SAÃDA DAS MÃ‰TRICAS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nğŸ“‹ MÃ©tricas Gerais:\")\n",
    "print(f\"   Total originais           : {formata_numero(total_original)}\")\n",
    "print(f\"   Duplicados removidos      : {formata_numero(n_duplicados)}\")\n",
    "print(f\"   Sem Abstract              : {formata_numero(n_sem_abstract)}\")\n",
    "print(f\"   Sem Affiliations          : {formata_numero(n_sem_affiliacao)}\")\n",
    "print(f\"   Sem Keywords              : {formata_numero(n_sem_keywords)}\")\n",
    "print(f\"   Total apÃ³s filtragem      : {formata_numero(total_filtrado)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*55)\n",
    "print(f\"â±ï¸ Tempo de execuÃ§Ã£o: {dur_str}\")\n",
    "print(f\"ğŸ“… Finalizado em: {fim:%d/%m/%Y %H:%M:%S} (FlorianÃ³polis | SC)\")\n",
    "print(\"=\"*55)\n",
    "print(f\"â†’ Arquivo salvo em: {output_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c0cf61-733a-4be8-85ad-f75f3ab017c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ï¸ InÃ­cio em: 2025-05-03 09:06:59 (FlorianÃ³polis | SC)\n",
      "\n",
      "ğŸ”„ Processando palavras-chaveâ€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13614/13614 [00:00<00:00, 32530.73linhas/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ Primeiras 15 linhas do DataFrame:\n",
      "            Palavra-chave  OcorrÃªncias  Porcentagem (%)\n",
      "      earnings management         1029             1.50\n",
      "    management accounting          791             1.16\n",
      "               accounting          790             1.16\n",
      "     corporate governance          571             0.84\n",
      "                 business          568             0.83\n",
      "management and accounting          534             0.78\n",
      "                  finance          277             0.41\n",
      "                economics          240             0.35\n",
      "           sustainability          227             0.33\n",
      "          risk management          212             0.31\n",
      "               management          211             0.31\n",
      "      financial reporting          189             0.28\n",
      "                     ifrs          173             0.25\n",
      "           accountability          161             0.24\n",
      "              performance          158             0.23\n",
      "\n",
      "ğŸ”¢ Total de palavras-chave mapeadas: 68.375\n",
      "\n",
      "ğŸ“Š RELATÃ“RIO FINAL â€” FREQUÃŠNCIA DE PALAVRAS-CHAVE\n",
      "=======================================================\n",
      "â†’ Total mapeado          : 68375\n",
      "â±ï¸ Tempo de execuÃ§Ã£o: 0:00:02\n",
      "ğŸ“… Finalizado em: 03/05/2025 09:07:01 (FlorianÃ³polis | SC)\n",
      "=======================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "keyword_analitico.py\n",
    "\n",
    "Script 2 para:\n",
    "  1) Ler planilha Excel \"Portfolio_analitico.xlsx\";\n",
    "  2) Extrair e limpar as 'Author Keywords';\n",
    "  3) Contar frequÃªncia e calcular porcentagem de ocorrÃªncia;\n",
    "  4) Mostrar barra de progresso;\n",
    "  5) Gerar grÃ¡fico Top-15 em PNG;\n",
    "  6) Exportar relatÃ³rio formatado em Excel (.xlsx);\n",
    "  7) Registrar data/hora de inÃ­cio e tÃ©rmino da execuÃ§Ã£o.\n",
    "\n",
    "USO NO CLUSTER UFSC (vLab JupyterLab ou SLURM):\n",
    "  â€¢ Coloque este script e o arquivo \"Portfolio_analitico.xlsx\" no mesmo diretÃ³rio.\n",
    "  â€¢ No terminal do vLab (Launcher â†’ Terminal), rode:\n",
    "      module load python/3.10 pandas matplotlib xlsxwriter openpyxl tqdm\n",
    "      python keyword_analitico.py\n",
    "  â€¢ OU submeta um job SLURM sem GPU:\n",
    "      #SBATCH --cpus-per-task=4\n",
    "      python keyword_analitico.py\n",
    "\n",
    "DEPENDÃŠNCIAS (serÃ£o instaladas automaticamente se ausentes):\n",
    "  pandas, openpyxl, matplotlib, xlsxwriter, tqdm\n",
    "\n",
    "Autor: G.O., Renato | NEIMAC | PPGC | UFSC | Mestrado  \n",
    "Data: 01-mai-2025\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "# â”€â”€â”€ 0) marca data/hora de inÃ­cio (fuso SÃ£o Paulo) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SP_TZ = ZoneInfo(\"America/Sao_Paulo\")\n",
    "inicio = datetime.now(SP_TZ)\n",
    "print(f\"â–¶ï¸ InÃ­cio em: {inicio:%Y-%m-%d %H:%M:%S} (FlorianÃ³polis | SC)\")\n",
    "\n",
    "# 1) Instalar dependÃªncias se faltarem\n",
    "def instalar_dependencias():\n",
    "    deps = ['pandas', 'openpyxl', 'matplotlib', 'xlsxwriter', 'tqdm']\n",
    "    for pkg in deps:\n",
    "        try:\n",
    "            __import__(pkg)\n",
    "        except ImportError:\n",
    "            print(f\"âš™ï¸ Instalando {pkg}...\")\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg])\n",
    "            import site; site.addsitedir(site.USER_SITE)\n",
    "            __import__(pkg)\n",
    "\n",
    "instalar_dependencias()\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 2) Define diretÃ³rio e arquivos\n",
    "base_dir    = Path.cwd()\n",
    "input_file  = base_dir / 'Portfolio_analitico.xlsx'\n",
    "output_xlsx = base_dir / 'keyword_analitico.xlsx'\n",
    "output_png  = base_dir / 'top15_keywords.png'\n",
    "\n",
    "# 3) Verifica existÃªncia do arquivo de entrada\n",
    "if not input_file.exists():\n",
    "    sys.exit(f\"â›” Arquivo de entrada nÃ£o encontrado: {input_file}\")\n",
    "\n",
    "# 4) Leitura e validaÃ§Ã£o\n",
    "df = pd.read_excel(input_file)\n",
    "if 'Author Keywords' not in df.columns:\n",
    "    sys.exit(\"â›” Coluna 'Author Keywords' nÃ£o encontrada.\")\n",
    "keywords_ser = df['Author Keywords'].dropna()\n",
    "\n",
    "# 5) FunÃ§Ã£o de simplificaÃ§Ã£o\n",
    "def simplify_keyword(kw: str) -> str:\n",
    "    patterns = [r'aasb\\s*\\d*', r'aaoifi\\s*', r'aaer\\s*', r'aacsb\\s*']\n",
    "    kw = kw.strip()\n",
    "    for pat in patterns:\n",
    "        kw = re.sub(pat, '', kw, flags=re.IGNORECASE).strip()\n",
    "    return kw.lower()\n",
    "\n",
    "# 6) ExtraÃ§Ã£o e limpeza com barra de progresso\n",
    "print(\"\\nğŸ”„ Processando palavras-chaveâ€¦\")\n",
    "irrelevant = [r'^\\d+$', r'^\\d+[a-z]$', r'century', r'audit act', r'^[a-z]{1,2}$']\n",
    "all_keywords = []\n",
    "for entry in tqdm(keywords_ser, unit='linhas'):\n",
    "    partes = re.split(r'[;,/|]+| - ', str(entry))\n",
    "    for kw in partes:\n",
    "        kw = re.sub(r'[^\\w\\s]', '', kw).strip().lower()\n",
    "        if (not kw\n",
    "            or any(re.search(p, kw) for p in irrelevant)\n",
    "            or len(kw.split()) > 3):\n",
    "            continue\n",
    "        kw = simplify_keyword(kw)\n",
    "        if not re.fullmatch(r'[a-z0-9 ]+', kw):\n",
    "            continue\n",
    "        all_keywords.append(kw)\n",
    "\n",
    "# 7) Contagem e percentual\n",
    "total = len(all_keywords)\n",
    "if total == 0:\n",
    "    sys.exit(\"â›” Nenhuma palavra-chave vÃ¡lida apÃ³s processamento.\")\n",
    "counts = Counter(all_keywords)\n",
    "\n",
    "# 8) Monta DataFrame de saÃ­da\n",
    "df_out = pd.DataFrame([\n",
    "    {'Palavra-chave': k, 'OcorrÃªncias': v, 'Porcentagem (%)': round(v/total*100, 2)}\n",
    "    for k, v in counts.items()\n",
    "])\n",
    "df_out = df_out.sort_values('OcorrÃªncias', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 9) SaÃ­da no terminal (preview + total)\n",
    "print(\"\\nğŸ¯ Primeiras 15 linhas do DataFrame:\")\n",
    "print(df_out.head(15).to_string(index=False))\n",
    "print(f\"\\nğŸ”¢ Total de palavras-chave mapeadas: {total:,}\".replace(',', '.'))\n",
    "\n",
    "# 10) GrÃ¡fico Top-15\n",
    "top15 = counts.most_common(15)\n",
    "if top15:\n",
    "    kws, vals = zip(*top15)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(kws, vals)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel('OcorrÃªncias')\n",
    "    plt.title('Top 15 Palavras-Chave')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_png)\n",
    "    plt.close()\n",
    "\n",
    "# 11) FormataÃ§Ã£o e exportaÃ§Ã£o Excel\n",
    "df_out['Porcentagem (%)'] = df_out['Porcentagem (%)']\\\n",
    "    .map(lambda x: f\"{x:.2f}\".replace('.', ',') + '%')\n",
    "with pd.ExcelWriter(output_xlsx, engine='xlsxwriter') as writer:\n",
    "    df_out.to_excel(writer, index=False, sheet_name='Resumo')\n",
    "    wb = writer.book\n",
    "    ws = writer.sheets['Resumo']\n",
    "    header_fmt = wb.add_format({'bold': True, 'align': 'center'})\n",
    "    text_fmt   = wb.add_format({'align': 'left'})\n",
    "    num_fmt    = wb.add_format({'num_format': '#,##0', 'align': 'right'})\n",
    "    for col_idx, _ in enumerate(df_out.columns):\n",
    "        ws.write(0, col_idx, df_out.columns[col_idx], header_fmt)\n",
    "    ws.set_column('A:A', 40, text_fmt)\n",
    "    ws.set_column('B:B', 15, num_fmt)\n",
    "    ws.set_column('C:C', 15, text_fmt)\n",
    "\n",
    "# â”€â”€â”€ 12) RelatÃ³rio final com data e duraÃ§Ã£o â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fim     = datetime.now(SP_TZ)\n",
    "duracao = str(fim - inicio).split('.')[0]\n",
    "print(\"\\nğŸ“Š RELATÃ“RIO FINAL â€” FREQUÃŠNCIA DE PALAVRAS-CHAVE\")\n",
    "print(\"=\"*55)\n",
    "print(f\"â†’ Total mapeado          : {total}\")\n",
    "print(f\"â±ï¸ Tempo de execuÃ§Ã£o: {duracao}\")\n",
    "print(f\"ğŸ“… Finalizado em: {fim:%d/%m/%Y %H:%M:%S} (FlorianÃ³polis | SC)\")\n",
    "print(\"=\"*55 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05d8ac82-76eb-4160-a3f7-aa37406d904a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 12:07:22,720 - INFO - pandas jÃ¡ instalado.\n",
      "2025-05-03 12:07:22,721 - INFO - openpyxl jÃ¡ instalado.\n",
      "2025-05-03 12:07:22,721 - INFO - xlsxwriter jÃ¡ instalado.\n",
      "2025-05-03 12:07:23,813 - INFO - torch jÃ¡ instalado.\n",
      "2025-05-03 12:07:23,998 - INFO - transformers jÃ¡ instalado.\n",
      "2025-05-03 12:07:24,368 - INFO - scikit-learn jÃ¡ instalado.\n",
      "2025-05-03 12:07:24,369 - INFO - tqdm jÃ¡ instalado.\n",
      "2025-05-03 12:07:24,369 - INFO - numpy jÃ¡ instalado.\n",
      "2025-05-03 12:07:24,601 - INFO - nltk jÃ¡ instalado.\n",
      "2025-05-03 12:07:24,602 - INFO - psutil jÃ¡ instalado.\n",
      "2025-05-03 12:07:24,857 - INFO - Inicializando stemmer...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ï¸ InÃ­cio em: 2025-05-03 09:07:24 (FlorianÃ³polis | SC)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Deseja ativar debug (s/n)?  s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 12:07:28,244 - DEBUG - Modo debug ativado.\n",
      "2025-05-03 12:07:28,245 - INFO - Verificando arquivo: /home/jovyan/Congresso UFSC2025/keyword_analitico.xlsx\n",
      "2025-05-03 12:07:28,245 - INFO - Carregando planilha Excel...\n",
      "2025-05-03 12:07:28,759 - INFO - Colunas encontradas: ['Palavra-chave', 'OcorrÃªncias', 'Porcentagem (%)']\n",
      "2025-05-03 12:07:28,761 - INFO - Coluna de frequÃªncia: OcorrÃªncias\n",
      "2025-05-03 12:07:28,762 - INFO - Usando device: cpu\n",
      "2025-05-03 12:07:28,762 - INFO - Carregando tokenizer e modelo BERT...\n",
      "2025-05-03 12:07:30.318653: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746274050.330247 2114694 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746274050.333490 2114694 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746274050.344219 2114694 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746274050.344233 2114694 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746274050.344235 2114694 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746274050.344236 2114694 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-03 12:07:30.348253: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-03 12:07:31,619 - INFO - Categorias inicializadas.\n",
      "2025-05-03 12:07:31,620 - INFO - Processando palavras-chave...\n",
      "2025-05-03 12:07:31,629 - INFO - Encontradas 26125 palavras-chave Ãºnicas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ CATEGORIAS ENCONTRADAS NO DICIONÃRIO:\n",
      "----------------------------------------\n",
      "1. avaliaÃ§Ã£o de desempenho\n",
      "2. comportamento organizacional\n",
      "3. custo\n",
      "4. educaÃ§Ã£o contÃ¡bil\n",
      "5. orÃ§amento\n",
      "6. outros temas\n",
      "7. sistema de controle gerencial\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 12:07:31,900 - INFO - Calculando embeddings para 26125 textos...\n",
      "2025-05-03 12:07:31,901 - INFO - MemÃ³ria disponÃ­vel: 1744.27 GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1661124cc632432c9c9d705a9be2e2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processando batches:   0%|          | 0/1633 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 12:08:19,881 - INFO - Embeddings calculados com sucesso.\n",
      "2025-05-03 12:08:19,962 - INFO - Calculando embeddings das categorias...\n",
      "2025-05-03 12:08:19,963 - INFO - Calculando embeddings para 7 textos...\n",
      "2025-05-03 12:08:19,964 - INFO - MemÃ³ria disponÃ­vel: 1749.90 GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e88d6e28844179bff2eaf6093c4833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processando batches:   0%|          | 0/1 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 12:08:20,082 - INFO - Embeddings calculados com sucesso.\n",
      "2025-05-03 12:08:20,083 - INFO - Classificando palavras-chave...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "385c4c46b7334985928e15abed19dedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classificando:   0%|          | 0/26125 [00:00<?, ?kw/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 12:08:24,434 - INFO - Salvando debug...\n",
      "2025-05-03 12:08:26,384 - INFO - Debug salvo em: /home/jovyan/Congresso UFSC2025/debug_dicionario_scores.xlsx\n",
      "2025-05-03 12:08:26,386 - INFO - Gerando sugestÃµes...\n",
      "2025-05-03 12:08:26,400 - INFO - SugestÃµes salvas em: /home/jovyan/Congresso UFSC2025/suggested_terms.xlsx\n",
      "2025-05-03 12:08:26,400 - INFO - Integrando sugestÃµes...\n",
      "2025-05-03 12:08:26,401 - INFO - Calculando embeddings para 20 textos...\n",
      "2025-05-03 12:08:26,401 - INFO - MemÃ³ria disponÃ­vel: 1751.91 GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5e39364426413ea15dcb8e4173900e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processando batches:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 12:08:26,551 - INFO - Embeddings calculados com sucesso.\n",
      "2025-05-03 12:08:26,556 - INFO - Atualizando descritores...\n",
      "2025-05-03 12:08:26,557 - INFO - Gerando dicionÃ¡rio final com duas colunas...\n",
      "2025-05-03 12:08:26,577 - INFO - DicionÃ¡rio salvo em: /home/jovyan/Congresso UFSC2025/Dicionario_Contabilidade_Gerencial.xlsx\n",
      "2025-05-03 12:08:26,578 - INFO - Gerando relatÃ³rio final...\n",
      "2025-05-03 12:08:26,578 - INFO - Script concluÃ­do com sucesso.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š DICIONÃRIO FINAL ATUALIZADO\n",
      "- OrÃ§amento: 8008 keywords\n",
      "- Sistema de Controle Gerencial: 2678 keywords\n",
      "- AvaliaÃ§Ã£o de desempenho: 2582 keywords\n",
      "- Outros Temas: 2125 keywords\n",
      "- Custo: 9310 keywords\n",
      "- EducaÃ§Ã£o ContÃ¡bil: 865 keywords\n",
      "- NÃ£o Classificado: 309 keywords\n",
      "- Comportamento Organizacional: 248 keywords\n",
      "ğŸ“… Finalizado em: 03/05/2025 09:08:26 (FlorianÃ³polis | SC)\n",
      "â±ï¸ Tempo de execuÃ§Ã£o: 0:01:01\n",
      "â†’ DicionÃ¡rio salvo em: Dicionario_Contabilidade_Gerencial.xlsx\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Dicionario_contabilidade_gerencial.py\n",
    "\n",
    "Script 3 para:\n",
    "  1) Carregar planilha Excel \"keyword_analitico.xlsx\" com contagem de frequÃªncia;\n",
    "  2) Classificar semanticamente cada palavra-chave em subÃ¡reas de Contabilidade Gerencial;\n",
    "  3) Ajustar automaticamente descritores de cada categoria com base nas top keywords nÃ£o classificadas;\n",
    "  4) Gerar e formatar o dicionÃ¡rio temÃ¡tico em Excel \"Dicionario_Contabilidade_Gerencial.xlsx\" com duas colunas (Categoria e Palavras-chave);\n",
    "  5) Salvar scores de similaridade em \"debug_dicionario_scores.xlsx\";\n",
    "  6) Salvar sugestÃµes de termos em \"suggested_terms.xlsx\".\n",
    "\n",
    "USO NO CLUSTER UFSC (JupyterLab ou SLURM):\n",
    "  â€¢ Instale dependÃªncias: pip install pandas openpyxl xlsxwriter torch transformers scikit-learn tqdm numpy nltk psutil\n",
    "  â€¢ No cluster: module load python/3.10 pandas torch transformers scikit-learn tqdm openpyxl xlsxwriter nltk\n",
    "  â€¢ Execute: python Dicionario_contabilidade_gerencial.py\n",
    "  â€¢ Para SLURM, use o script fornecido no final.\n",
    "\n",
    "IMPORTANTE:\n",
    "  â€¢ A planilha \"keyword_analitico.xlsx\" deve ter colunas 'Palavra-chave' e uma coluna de frequÃªncia (nome com 'freq', 'count' ou 'ocorr').\n",
    "  â€¢ Arquivo deve estar no mesmo diretÃ³rio do script (/home/jovyan/Congresso UFSC2025/).\n",
    "  â€¢ A saÃ­da do dicionÃ¡rio serÃ¡ ajustada para apenas \"Categoria\" e \"Palavras-chave\" com todas as palavras classificadas.\n",
    "\n",
    "DEPENDÃŠNCIAS:\n",
    "  pandas, openpyxl, xlsxwriter, torch, transformers, scikit-learn, tqdm, numpy, nltk, psutil\n",
    "\n",
    "Autor: G.O., Renato | NEIMAC | PPGC | UFSC | Mestrado\n",
    "Contribuidores: [Adicione seu nome, se aplicÃ¡vel]\n",
    "LicenÃ§a: MIT\n",
    "Data: 02/05/2025\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import re\n",
    "import os\n",
    "import logging\n",
    "import psutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Desativar TensorFlow CUDA e oneDNN\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''  # Desativa GPU\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # Desativa oneDNN\n",
    "\n",
    "# Instalar dependÃªncias\n",
    "def instalar_dependencias():\n",
    "    \"\"\"Instala as dependÃªncias necessÃ¡rias se nÃ£o estiverem disponÃ­veis.\"\"\"\n",
    "    deps = ['pandas', 'openpyxl', 'xlsxwriter', 'torch', 'transformers', 'scikit-learn', 'tqdm', 'numpy', 'nltk', 'psutil']\n",
    "    for pkg in deps:\n",
    "        mod = 'sklearn' if pkg == 'scikit-learn' else pkg\n",
    "        try:\n",
    "            __import__(mod)\n",
    "            logger.info(f\"{pkg} jÃ¡ instalado.\")\n",
    "        except ImportError:\n",
    "            logger.info(f\"Instalando {pkg}...\")\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg])\n",
    "            import site\n",
    "            site.addsitedir(site.USER_SITE)\n",
    "\n",
    "try:\n",
    "    instalar_dependencias()\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao instalar dependÃªncias: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "try:\n",
    "    from tqdm.notebook import tqdm  # Para JupyterLab\n",
    "except ImportError:\n",
    "    from tqdm import tqdm  # Fallback para terminal\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Inicializar stemmer\n",
    "logger.info(\"Inicializando stemmer...\")\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "# Definir caminhos e timezone\n",
    "base_dir = Path.cwd()\n",
    "input_file = base_dir / 'keyword_analitico.xlsx'\n",
    "output_file = base_dir / 'Dicionario_Contabilidade_Gerencial.xlsx'\n",
    "debug_file = base_dir / 'debug_dicionario_scores.xlsx'\n",
    "sugg_file = base_dir / 'suggested_terms.xlsx'\n",
    "\n",
    "SC_TZ = ZoneInfo('America/Sao_Paulo')\n",
    "inicio = datetime.now(SC_TZ)\n",
    "\n",
    "# Exibir inÃ­cio\n",
    "print(f\"â–¶ï¸ InÃ­cio em: {inicio:%Y-%m-%d %H:%M:%S} (FlorianÃ³polis | SC)\")\n",
    "\n",
    "# Perguntar sobre debug\n",
    "debug_mode = input(\"Deseja ativar debug (s/n)? \").strip().lower() == 's'\n",
    "if debug_mode:\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logger.debug(\"Modo debug ativado.\")\n",
    "\n",
    "# Verificar arquivo de entrada\n",
    "logger.info(f\"Verificando arquivo: {input_file}\")\n",
    "if not input_file.exists():\n",
    "    logger.error(f\"Arquivo {input_file} nÃ£o encontrado.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Carregar planilha\n",
    "logger.info(\"Carregando planilha Excel...\")\n",
    "try:\n",
    "    df = pd.read_excel(input_file)\n",
    "    logger.info(f\"Colunas encontradas: {list(df.columns)}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao carregar planilha: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "freq_cols = [c for c in df.columns if any(x in c.lower() for x in ['freq', 'count', 'ocorr'])]\n",
    "if 'Palavra-chave' not in df.columns or not freq_cols:\n",
    "    logger.error(\"A planilha deve ter colunas 'Palavra-chave' e frequÃªncia (com 'freq', 'count' ou 'ocorr').\")\n",
    "    sys.exit(1)\n",
    "freq_col = freq_cols[0]\n",
    "logger.info(f\"Coluna de frequÃªncia: {freq_col}\")\n",
    "\n",
    "# Configurar dispositivo e modelo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info(f\"Usando device: {device}\")\n",
    "try:\n",
    "    logger.info(\"Carregando tokenizer e modelo BERT...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "    model = AutoModel.from_pretrained('bert-base-multilingual-cased').to(device)\n",
    "    model.eval()\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao carregar modelo BERT: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Definir descritores das categorias (atualizado com as palavras sugeridas)\n",
    "categorias = {\n",
    "    'AvaliaÃ§Ã£o de desempenho': (\n",
    "        'performance management; performance evaluation; performance appraisal; performance measurement;'\n",
    "        'kpi; roi; roa; bsc; balanced scorecard; benchmarking; efficiency analysis; value-based performance;'\n",
    "        'economic value added; eva; employee performance; performance review; productivity metrics;'\n",
    "        'performance feedback; goal setting; performance indicators; outcome measurement; performance tracking;'\n",
    "        'performance standards; employee appraisal; performance assessment; organizational metrics;'\n",
    "        'performance improvement'\n",
    "    ),\n",
    "    'OrÃ§amento': (\n",
    "        'budgeting; budget planning; budget forecast; budget participation; budgetary control; beyond budgeting;'\n",
    "        'rolling forecast; zero-based budgeting; incremental budgeting; budget constraints; budget approval;'\n",
    "        'budget cycle; budget preparation; budget allocation; budget review; budget oversight'\n",
    "    ),\n",
    "    'Custo': (\n",
    "        'cost accounting; cost systems; abc costing; activity-based costing; absorption costing;'\n",
    "        'variable costing; target costing; kaizen costing; standard costing; life cycle costing;'\n",
    "        'cost control; cost analysis; cost estimate; cost drivers; cost behavior; '\n",
    "        'direct costs; indirect costs; cost structure; unit cost'\n",
    "    ),\n",
    "    'Sistema de Controle Gerencial': (\n",
    "        'management control systems; mcs; control systems; levers of control; belief systems;'\n",
    "        'boundary systems; strategic control; operational control; internal control systems;'\n",
    "        'accounting information systems; results control; action control; diagnostic control;'\n",
    "        'interactive control; control mechanisms; control practices; control frameworks;'\n",
    "        'management accounting systems; control policies; control feedback mechanisms; control processes;'\n",
    "        'management oversight; control implementation'\n",
    "    ),\n",
    "    'Comportamento Organizacional': (\n",
    "        'organizational behavior; employee engagement; motivation theories; cognitive bias;'\n",
    "        'organizational culture; leadership styles; team dynamics; organizational commitment;'\n",
    "        'psychological safety; work motivation; workplace behavior; job satisfaction;'\n",
    "        'organizational justice; organizational psychology; affective commitment; job involvement;'\n",
    "        'turnover intention; group behavior; interpersonal conflict; communication styles;'\n",
    "        'power dynamics; organizational learning; diversity management; emotional intelligence;'\n",
    "        'behavioral decision-making; team performance; workplace dynamics; employee motivation;'\n",
    "        'organizational change; conflict resolution'\n",
    "    ),\n",
    "    'EducaÃ§Ã£o ContÃ¡bil': (\n",
    "        'accounting education; curriculum development; teaching methods; learning strategies;'\n",
    "        'pedagogy in higher education; professional development; continuing education; instructional design;'\n",
    "        'accounting instructor; accounting teaching; educational innovation; didactic strategies;'\n",
    "        'blended learning; teaching accounting; student academic performance; learning outcomes; capstone course;'\n",
    "        'ethics education; teaching cases; IFRS education; audit education; tax education; critical thinking;'\n",
    "        'student assessment; accounting skills; competency-based education; student engagement;'\n",
    "        'accounting students; accounting pedagogy; accounting curriculum; student learning;'\n",
    "        'accounting certification; accounting faculty; accounting courses; student accounting skills;'\n",
    "        'accounting departments; academic accounting; accounting academics; accounting research education'\n",
    "    ),\n",
    "    'Outros Temas': (\n",
    "        'general business trends; non-specific industry topics; miscellaneous organizational concepts;'\n",
    "        'emerging technologies; social impact initiatives; global economic trends; cross-industry innovation;'\n",
    "        'non-accounting academic research; societal trends; cultural studies; public administration;'\n",
    "        'nonprofit management; social entrepreneurship; community development; human rights; gender equality;'\n",
    "        'environmental policy; urban development; smart cities; systemic change'\n",
    "    )\n",
    "}\n",
    "\n",
    "# Exibir categorias encontradas\n",
    "print(\"ğŸ“‹ CATEGORIAS ENCONTRADAS NO DICIONÃRIO:\")\n",
    "print(\"----------------------------------------\")\n",
    "for i, cat in enumerate(sorted(categorias.keys()), 1):\n",
    "    print(f\"{i}. {cat.lower()}\")\n",
    "print(\"----------------------------------------\")\n",
    "logger.info(\"Categorias inicializadas.\")\n",
    "\n",
    "# FunÃ§Ã£o de embedding\n",
    "def embed_texts(texts, batch_size=16):\n",
    "    \"\"\"Gera embeddings para uma lista de textos usando BERT.\"\"\"\n",
    "    logger.info(f\"Calculando embeddings para {len(texts)} textos...\")\n",
    "    mem = psutil.virtual_memory()\n",
    "    logger.info(f\"MemÃ³ria disponÃ­vel: {mem.available / (1024**3):.2f} GB\")\n",
    "    if mem.available < 1 * (1024**3):\n",
    "        logger.warning(\"MemÃ³ria baixa! Pode causar travamento.\")\n",
    "    embs = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Processando batches\", unit=\"batch\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        try:\n",
    "            enc = tokenizer(batch, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "            with torch.no_grad():\n",
    "                out = model(**enc).last_hidden_state\n",
    "            embs.append(out.mean(1).cpu().numpy())\n",
    "            torch.cuda.empty_cache() if device.type == 'cuda' else None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erro no batch {i//batch_size + 1}: {e}\")\n",
    "            raise\n",
    "    logger.info(\"Embeddings calculados com sucesso.\")\n",
    "    return np.vstack(embs)\n",
    "\n",
    "# Processar palavras-chave\n",
    "logger.info(\"Processando palavras-chave...\")\n",
    "unique_kws = sorted(df['Palavra-chave'].astype(str).unique())\n",
    "logger.info(f\"Encontradas {len(unique_kws)} palavras-chave Ãºnicas.\")\n",
    "stems = [' '.join(stemmer.stem(tok) for tok in re.findall(r\"\\w+\", kw.lower())) for kw in unique_kws]\n",
    "try:\n",
    "    kw_emb = embed_texts(stems)\n",
    "    kw_emb /= np.linalg.norm(kw_emb, axis=1, keepdims=True)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao calcular embeddings das palavras-chave: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Embeddings das categorias\n",
    "logger.info(\"Calculando embeddings das categorias...\")\n",
    "descs = list(categorias.values())\n",
    "cat_keys = list(categorias.keys())\n",
    "try:\n",
    "    cat_emb = embed_texts(descs)\n",
    "    cat_emb /= np.linalg.norm(cat_emb, axis=1, keepdims=True)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao calcular embeddings das categorias: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Regras manuais de reclassificaÃ§Ã£o baseadas na anÃ¡lise\n",
    "reclass_rules = {\n",
    "    '6g cellular communication': 'Outros Temas',\n",
    "    '1c company': 'Sistema de Controle Gerencial',\n",
    "    '401k investment': 'OrÃ§amento',\n",
    "    '2003 northeast blackout': 'Outros Temas',\n",
    "    '10k report': 'AvaliaÃ§Ã£o de desempenho',\n",
    "    'a76 studies': 'Outros Temas',\n",
    "    'team productivity': 'Comportamento Organizacional',\n",
    "    'planning and budgeting': 'OrÃ§amento',\n",
    "    'audit committee': 'Outros Temas',\n",
    "    'digital technologies': 'Outros Temas',\n",
    "    'learning curve': 'EducaÃ§Ã£o ContÃ¡bil',\n",
    "}\n",
    "\n",
    "# Classificar palavras-chave\n",
    "logger.info(\"Classificando palavras-chave...\")\n",
    "debug = []\n",
    "cats_assigned = []\n",
    "for idx, emb in enumerate(tqdm(kw_emb, desc='Classificando', unit='kw')):\n",
    "    kw = unique_kws[idx]\n",
    "    if kw in reclass_rules:\n",
    "        cat = reclass_rules[kw]\n",
    "    else:\n",
    "        sims = cosine_similarity([emb], cat_emb)[0]\n",
    "        imax = sims.argmax()\n",
    "        cat = cat_keys[imax] if sims[imax] >= 0.3 else 'NÃ£o Classificado'  # Mantido limiar em 0.3\n",
    "    cats_assigned.append(cat)\n",
    "    debug.append({'keyword': kw, **{cat_keys[i]: float(sims[i]) for i in range(len(cat_keys))}, 'assigned': cat})\n",
    "\n",
    "# Contar palavras por categoria\n",
    "word_counts = Counter(cats_assigned)\n",
    "\n",
    "# Salvar debug\n",
    "logger.info(\"Salvando debug...\")\n",
    "try:\n",
    "    debug_df = pd.DataFrame(debug)\n",
    "    debug_df.to_excel(debug_file, index=False)\n",
    "    logger.info(f\"Debug salvo em: {debug_file}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao salvar debug: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# SugestÃµes de termos\n",
    "logger.info(\"Gerando sugestÃµes...\")\n",
    "nao_cl = debug_df[debug_df.assigned == 'NÃ£o Classificado'][['keyword']].drop_duplicates()\n",
    "freq_df = df[['Palavra-chave', freq_col]].rename(columns={'Palavra-chave': 'keyword', freq_col: 'frequency'})\n",
    "sugg = nao_cl.merge(freq_df, on='keyword', how='left').sort_values('frequency', ascending=False).head(20)\n",
    "try:\n",
    "    sugg.to_excel(sugg_file, index=False)\n",
    "    logger.info(f\"SugestÃµes salvas em: {sugg_file}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao salvar sugestÃµes: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Integrar sugestÃµes\n",
    "logger.info(\"Integrando sugestÃµes...\")\n",
    "new_terms = defaultdict(list)\n",
    "sugg_stems = [' '.join(stemmer.stem(tok) for tok in re.findall(r\"\\w+\", kw.lower())) for kw in sugg.keyword]\n",
    "try:\n",
    "    sugg_emb = embed_texts(sugg_stems)\n",
    "    sugg_emb /= np.linalg.norm(sugg_emb, axis=1, keepdims=True)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao calcular embeddings das sugestÃµes: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "for kw, emb in zip(sugg.keyword, sugg_emb):\n",
    "    sims = cosine_similarity([emb], cat_emb)[0]\n",
    "    imax = sims.argmax()\n",
    "    cat = cat_keys[imax] if sims[imax] >= 0.3 else None  # Mantido limiar em 0.3\n",
    "    if cat:\n",
    "        new_terms[cat].append(kw)\n",
    "\n",
    "# Atualizar descritores\n",
    "logger.info(\"Atualizando descritores...\")\n",
    "for cat, terms in new_terms.items():\n",
    "    if terms:\n",
    "        categorias[cat] += '; ' + '; '.join(terms)\n",
    "\n",
    "# Gerar dicionÃ¡rio com duas colunas\n",
    "logger.info(\"Gerando dicionÃ¡rio final com duas colunas...\")\n",
    "try:\n",
    "    # Criar dicionÃ¡rio com palavras classificadas\n",
    "    cat_words = defaultdict(list)\n",
    "    for kw, cat in zip(unique_kws, cats_assigned):\n",
    "        cat_words[cat].append(kw)\n",
    "    dict_df = pd.DataFrame([\n",
    "        (cat, '; '.join(sorted(words))) for cat, words in cat_words.items()\n",
    "    ], columns=['Categoria', 'Palavras-chave'])\n",
    "    dict_df = dict_df.sort_values('Categoria')\n",
    "    \n",
    "    # Salvar no Excel\n",
    "    with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "        dict_df.to_excel(writer, index=False, sheet_name='DicionÃ¡rio')\n",
    "        wb = writer.book\n",
    "        ws = writer.sheets['DicionÃ¡rio']\n",
    "        fmt = wb.add_format({'font_name': 'Times New Roman', 'font_size': 12, 'align': 'center', 'valign': 'vcenter'})\n",
    "        ws.set_column('A:A', 25, fmt)\n",
    "        ws.set_column('B:B', 80, fmt)\n",
    "    logger.info(f\"DicionÃ¡rio salvo em: {output_file}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao gerar dicionÃ¡rio: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# RelatÃ³rio final\n",
    "logger.info(\"Gerando relatÃ³rio final...\")\n",
    "fim = datetime.now(SC_TZ)\n",
    "dur = str(fim - inicio).split('.')[0]\n",
    "\n",
    "print(\"ğŸ“Š DICIONÃRIO FINAL ATUALIZADO\")\n",
    "for c, n in word_counts.items():\n",
    "    print(f\"- {c}: {n} keywords\")\n",
    "print(f\"ğŸ“… Finalizado em: {fim:%d/%m/%Y %H:%M:%S} (FlorianÃ³polis | SC)\")\n",
    "print(f\"â±ï¸ Tempo de execuÃ§Ã£o: {dur}\")\n",
    "print(f\"â†’ DicionÃ¡rio salvo em: {output_file.name}\")\n",
    "logger.info(\"Script concluÃ­do com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "401648ec-0bef-43ea-afb8-d1bd4d406186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ï¸ InÃ­cio em: 2025-05-03 09:10:07 (FlorianÃ³polis | SC)\n",
      "Baixando recursos do NLTK...\n",
      "Recursos do NLTK baixados com sucesso.\n",
      "Carregando /home/jovyan/Congresso UFSC2025/Dicionario_Contabilidade_Gerencial.xlsx...\n",
      "DicionÃ¡rio carregado com 8 categorias.\n",
      "Carregando /home/jovyan/Congresso UFSC2025/SJR 2023.xls...\n",
      "SJR 2023 carregado com 1576 entradas.\n",
      "Carregando /home/jovyan/Congresso UFSC2025/Portfolio_analitico.xlsx...\n",
      "Planilha de artigos carregada com 13614 linhas.\n",
      "Extraindo paÃ­ses da coluna 'Affiliations'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13614/13614 [00:00<00:00, 794573.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associando 'Best Quartile' com base no SJR 2023...\n",
      "Classificando artigos por temÃ¡tica...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13614/13614 [00:06<00:00, 2029.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvando resultado em /home/jovyan/Congresso UFSC2025/Portfolio_analitico_classificado.xlsx...\n",
      "\n",
      "Resumo de artigos por categoria:\n",
      "               Grupo TemÃ¡tico  Contagem\n",
      "                    OrÃ§amento      3485\n",
      "             NÃ£o Classificado      2691\n",
      "                        Custo      2025\n",
      " Comportamento Organizacional      1364\n",
      "                 Outros Temas      1268\n",
      "Sistema de Controle Gerencial      1258\n",
      "      AvaliaÃ§Ã£o de desempenho       933\n",
      "            EducaÃ§Ã£o ContÃ¡bil       590\n",
      "\n",
      "ğŸ“… Finalizado em: 03/05/2025 09:10:18 (FlorianÃ³polis | SC)\n",
      "â±ï¸ Tempo de execuÃ§Ã£o: 0h 0m 10s\n",
      "â†’ ClassificaÃ§Ã£o salva em: Portfolio_analitico_classificado.xlsx\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "classificar_artigos_tematica.py (VersÃ£o Ajustada Final)\n",
    "\n",
    "Script 4 para:\n",
    "  1) NormalizaÃ§Ã£o dos scores por nÃºmero de descritores por categoria.\n",
    "  2) AdiÃ§Ã£o de n-gramas para capturar expressÃµes compostas.\n",
    "  3) PrÃ©-processamento com remoÃ§Ã£o de stop words, pontuaÃ§Ã£o e normalizaÃ§Ã£o.\n",
    "  4) OtimizaÃ§Ã£o com Ã­ndice invertido.\n",
    "  5) InclusÃ£o de debug para anÃ¡lise dos scores.\n",
    "\n",
    "USO NO CLUSTER UFSC (JupyterLab ou SLURM):\n",
    "  â€¢ Instale dependÃªncias: pip install pandas openpyxl nltk tqdm\n",
    "  â€¢ No cluster: module load python/3.10 pandas openpyxl nltk\n",
    "  â€¢ Execute: python classificar_artigos_tematica.py\n",
    "  â€¢ Arquivos devem estar no mesmo diretÃ³rio.\n",
    "\n",
    "IMPORTANTE:\n",
    "  â€¢ \"Portfolio_analitico.xlsx\" deve ter as colunas 'Year', 'Cited by', 'Title', 'Abstract', 'Affiliations', 'Source title', 'Author Keywords'.\n",
    "  â€¢ \"Dicionario_Contabilidade_Gerencial.xlsx\" e \"SJR 2023.xlsx\" devem estar no diretÃ³rio atual.\n",
    "  â€¢ SaÃ­da serÃ¡ salva como \"Portfolio_analitico_classificado.xlsx\" com as abas 'ClassificaÃ§Ã£o' e 'Resumo_Categorias'.\n",
    "\n",
    "DEPENDÃŠNCIAS:\n",
    "  pandas, openpyxl, nltk, tqdm\n",
    "\n",
    "Autor: G.O., Renato | NEIMAC | PPGC | UFSC | Mestrado\n",
    "RevisÃµes: Grok (xAI)\n",
    "Data: 02/05/2025\n",
    "LicenÃ§a: MIT (CiÃªncia Aberta - Open Science Framework)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Definir timezone e marcar inÃ­cio\n",
    "SC_TZ = ZoneInfo('America/Sao_Paulo')\n",
    "inicio = datetime.now(SC_TZ)\n",
    "\n",
    "print(f\"â–¶ï¸ InÃ­cio em: {inicio:%Y-%m-%d %H:%M:%S} (FlorianÃ³polis | SC)\")\n",
    "\n",
    "# Inicializar NLTK e baixar os recursos necessÃ¡rios\n",
    "print(\"Baixando recursos do NLTK...\")\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "print(\"Recursos do NLTK baixados com sucesso.\")\n",
    "\n",
    "# Habilitar progresso com pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Definir caminhos\n",
    "base_dir = Path.cwd()\n",
    "input_dict_file = base_dir / 'Dicionario_Contabilidade_Gerencial.xlsx'\n",
    "input_sjr_file = base_dir / 'SJR 2023.xls'\n",
    "input_artigos_file = base_dir / 'Portfolio_analitico.xlsx'\n",
    "output_file = base_dir / 'Portfolio_analitico_classificado.xlsx'\n",
    "\n",
    "# Carregar o dicionÃ¡rio temÃ¡tico\n",
    "print(f\"Carregando {input_dict_file}...\")\n",
    "try:\n",
    "    dict_df = pd.read_excel(input_dict_file)\n",
    "    categorias = dict_df.set_index('Categoria')['Palavras-chave'].to_dict()\n",
    "    print(f\"DicionÃ¡rio carregado com {len(categorias)} categorias.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: Arquivo {input_dict_file} nÃ£o encontrado.\")\n",
    "    exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar o dicionÃ¡rio: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Construir Ã­ndice invertido para otimizaÃ§Ã£o\n",
    "def build_inverted_index(categorias):\n",
    "    index = {}\n",
    "    palavras_por_categoria = {}\n",
    "    for categoria, palavras in categorias.items():\n",
    "        palavras_lista = re.split(r'[,;]\\s*', palavras.lower())\n",
    "        palavras_por_categoria[categoria] = len(palavras_lista)\n",
    "        for palavra in palavras_lista:\n",
    "            if palavra not in index:\n",
    "                index[palavra] = []\n",
    "            index[palavra].append(categoria)\n",
    "    return index, palavras_por_categoria\n",
    "\n",
    "inverted_index, palavras_por_categoria = build_inverted_index(categorias)\n",
    "\n",
    "# Carregar o arquivo SJR 2023\n",
    "print(f\"Carregando {input_sjr_file}...\")\n",
    "try:\n",
    "    sjr_df = pd.read_excel(input_sjr_file)\n",
    "    if not all(col in sjr_df.columns for col in ['Title', 'Best Quartile']):\n",
    "        print(\"Erro: A planilha 'SJR 2023.xls' deve ter as colunas 'Title' e 'Best Quartile'.\")\n",
    "        exit(1)\n",
    "    sjr_dict = pd.Series(\n",
    "        sjr_df['Best Quartile'].values,\n",
    "        index=sjr_df['Title'].str.lower().str.strip()\n",
    "    ).to_dict()\n",
    "    print(f\"SJR 2023 carregado com {len(sjr_dict)} entradas.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: Arquivo {input_sjr_file} nÃ£o encontrado.\")\n",
    "    exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar o arquivo SJR: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Carregar a planilha de artigos\n",
    "print(f\"Carregando {input_artigos_file}...\")\n",
    "try:\n",
    "    artigos_df = pd.read_excel(input_artigos_file)\n",
    "    expected_cols = ['Year', 'Cited by', 'Title', 'Abstract', 'Affiliations', 'Source title', 'Author Keywords']\n",
    "    if not all(col in artigos_df.columns for col in expected_cols):\n",
    "        print(f\"Erro: A planilha 'Portfolio_analitico.xlsx' deve ter as colunas {expected_cols}.\")\n",
    "        print(f\"Colunas disponÃ­veis: {artigos_df.columns.tolist()}\")\n",
    "        exit(1)\n",
    "    print(f\"Planilha de artigos carregada com {len(artigos_df)} linhas.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: Arquivo {input_artigos_file} nÃ£o encontrado.\")\n",
    "    exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar os artigos: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# FunÃ§Ãµes utilitÃ¡rias\n",
    "def extrair_pais(affiliations):\n",
    "    if pd.isna(affiliations) or affiliations == '':\n",
    "        return ''\n",
    "    aff_text = str(affiliations).split(';')[0]\n",
    "    if ',' in aff_text:\n",
    "        pais = aff_text.split(',')[-1].strip()\n",
    "        return pais if pais else 'NÃ£o Identificado'\n",
    "    return 'NÃ£o Identificado'\n",
    "\n",
    "# PrÃ©-processamento de texto\n",
    "stop_words = set(stopwords.words('english') + stopwords.words('portuguese'))\n",
    "def preprocess_text(texto):\n",
    "    texto = str(texto).lower()\n",
    "    texto = re.sub(r'[^\\w\\s]', '', texto)  # Remover pontuaÃ§Ã£o\n",
    "    texto_tokens = word_tokenize(texto)\n",
    "    texto_tokens = [t for t in texto_tokens if t not in stop_words]\n",
    "    # Adicionar bigramas\n",
    "    bigrams = [' '.join(ng) for ng in ngrams(texto_tokens, 2)]\n",
    "    texto_tokens.extend(bigrams)\n",
    "    return texto_tokens\n",
    "\n",
    "# FunÃ§Ã£o de classificaÃ§Ã£o com debug\n",
    "def classificar_artigo(texto):\n",
    "    texto_tokens = preprocess_text(texto)\n",
    "    categoria_counts = {}\n",
    "    for token in texto_tokens:\n",
    "        if token in inverted_index:\n",
    "            for categoria in inverted_index[token]:\n",
    "                categoria_counts[categoria] = categoria_counts.get(categoria, 0) + 1\n",
    "    scores = {}\n",
    "    melhor_categoria = None\n",
    "    max_taxa = 0\n",
    "    min_correspondencias = 2  # Limiar mÃ­nimo\n",
    "    for categoria, count in categoria_counts.items():\n",
    "        if count >= min_correspondencias:\n",
    "            taxa = count / palavras_por_categoria[categoria]\n",
    "            scores[categoria] = taxa\n",
    "            if taxa > max_taxa:\n",
    "                max_taxa = taxa\n",
    "                melhor_categoria = categoria\n",
    "        else:\n",
    "            scores[categoria] = 0\n",
    "    return melhor_categoria if melhor_categoria else 'NÃ£o Classificado', scores\n",
    "\n",
    "# Processamento das colunas\n",
    "print(\"Extraindo paÃ­ses da coluna 'Affiliations'...\")\n",
    "artigos_df['PaÃ­s'] = artigos_df['Affiliations'].progress_apply(extrair_pais)\n",
    "\n",
    "print(\"Associando 'Best Quartile' com base no SJR 2023...\")\n",
    "artigos_df['Best Quartile'] = (\n",
    "    artigos_df['Source title']\n",
    "    .str.lower().str.strip()\n",
    "    .map(sjr_dict)\n",
    "    .fillna('NÃ£o Encontrado')\n",
    ")\n",
    "\n",
    "print(\"Classificando artigos por temÃ¡tica...\")\n",
    "resultados = artigos_df.progress_apply(\n",
    "    lambda row: classificar_artigo(\n",
    "        ' '.join([str(row['Title']), str(row['Abstract']), str(row['Author Keywords'])])\n",
    "    ), axis=1\n",
    ")\n",
    "artigos_df['Grupo TemÃ¡tico'] = [res[0] for res in resultados]\n",
    "artigos_df['Debug_Scores'] = [str(res[1]) for res in resultados]\n",
    "\n",
    "# Reorganizar colunas\n",
    "final_columns = ['Year', 'Cited by', 'Title', 'Abstract', 'Affiliations', 'PaÃ­s',\n",
    "                 'Source title', 'Best Quartile', 'Author Keywords', 'Grupo TemÃ¡tico', 'Debug_Scores']\n",
    "artigos_df = artigos_df[final_columns]\n",
    "\n",
    "# Salvar resultados\n",
    "print(f\"Salvando resultado em {output_file}...\")\n",
    "try:\n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        artigos_df.to_excel(writer, index=False, sheet_name='ClassificaÃ§Ã£o')\n",
    "        resumo_df = (\n",
    "            artigos_df['Grupo TemÃ¡tico']\n",
    "            .value_counts()\n",
    "            .rename_axis('Grupo TemÃ¡tico')\n",
    "            .reset_index(name='Contagem')\n",
    "        )\n",
    "        resumo_df.to_excel(writer, index=False, sheet_name='Resumo_Categorias')\n",
    "    print(\"\\nResumo de artigos por categoria:\")\n",
    "    print(resumo_df.to_string(index=False))\n",
    "\n",
    "    fim = datetime.now(SC_TZ)\n",
    "    dur = fim - inicio\n",
    "    horas, resto = divmod(dur.seconds, 3600)\n",
    "    minutos, segundos = divmod(resto, 60)\n",
    "    print(f\"\\nğŸ“… Finalizado em: {fim:%d/%m/%Y %H:%M:%S} (FlorianÃ³polis | SC)\")\n",
    "    print(f\"â±ï¸ Tempo de execuÃ§Ã£o: {horas}h {minutos}m {segundos}s\")\n",
    "    print(f\"â†’ ClassificaÃ§Ã£o salva em: {output_file.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao salvar a classificaÃ§Ã£o: {e}\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b3b630b-39c8-4164-90b0-3ba1e6860ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ï¸ InÃ­cio em: 2025-05-03 09:12:56 (FlorianÃ³polis | SC)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 12:12:59,748 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ï¸ Usando device: cpu\n",
      "\n",
      "â³ Gerando embeddings dos tÃ­tulos...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d3b3b91ddb4c3bb4e3185018acff6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Gerando embeddings dos resumos...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ca28352b414ee296b008eb59216686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ Calculando similaridades tÃ­tulo vs. resumo...\n",
      "\n",
      "===== RELATÃ“RIO FINAL =====\n",
      "Total analisados       : 13.614\n",
      "Alta CoerÃªncia         : 1.179 (8.7%)\n",
      "MÃ©dia CoerÃªncia        : 8.573 (63.0%)\n",
      "Baixa CoerÃªncia        : 3.862 (28.4%)\n",
      "Sem dados/Erro         : 0 (0.0%)\n",
      "Tempo de execuÃ§Ã£o: 0:01:37\n",
      "Finalizado em: 2025-05-03 09:14:33 (FlorianÃ³polis | SC)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "coerencia_comunicacional.py\n",
    "\n",
    "Script 5 para:\n",
    "  1) Ler Portfolio_analitico_classificado.xlsx e preservar dados & formataÃ§Ã£o da coluna J;\n",
    "  2) Calcular score de coerÃªncia tÃ­tulo vs. resumo com SBERT em batch;\n",
    "  3) Gerar histogramas e boxplot;\n",
    "  4) Destacar 1% de piores coerÃªncias nas colunas C e D;\n",
    "  5) Restaurar coluna J, formatar planilha e salvar em Portfolio_analitico_coerencia.xlsx;\n",
    "  6) Exibir relatÃ³rio final com contagens, tempo e data de execuÃ§Ã£o.\n",
    "\n",
    "USO NO CLUSTER UFSC (JupyterLab ou SLURM):\n",
    "  â€¢ Carregue GPU e Python 3.10:\n",
    "      module load cuda/11.7 python/3.10\n",
    "  â€¢ Execute:\n",
    "      python coerencia_comunicacional.py\n",
    "\n",
    "DEPENDÃŠNCIAS (serÃ£o instaladas automaticamente):\n",
    "  sentence-transformers, pandas, openpyxl, tqdm, matplotlib\n",
    "\n",
    "Autor: G.O., Renato | NEIMAC | PPGC | UFSC | Mestrado\n",
    "Data: 02/05/2025\n",
    "\"\"\"\n",
    "\n",
    "import sys, subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill, Font, Alignment\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 0) Instala deps se necessÃ¡rio\n",
    "def instalar(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "for pkg in (\"sentence-transformers\",\"pandas\",\"openpyxl\",\"tqdm\",\"matplotlib\"):\n",
    "    try:\n",
    "        __import__(pkg.replace('-', '_'))\n",
    "    except ImportError:\n",
    "        print(f\"âš™ï¸ Instalando {pkg}...\")\n",
    "        instalar(pkg)\n",
    "\n",
    "# --- INÃCIO (fuso SÃ£o Paulo) -------------------------------------\n",
    "SP_TZ       = ZoneInfo(\"America/Sao_Paulo\")\n",
    "data_inicio = datetime.now(SP_TZ)\n",
    "print(f\"â–¶ï¸ InÃ­cio em: {data_inicio:%Y-%m-%d %H:%M:%S} (FlorianÃ³polis | SC)\\n\")\n",
    "\n",
    "# 1) Caminhos de entrada e saÃ­da\n",
    "def get_paths():\n",
    "    try:\n",
    "        base = Path(__file__).resolve().parent\n",
    "    except NameError:\n",
    "        base = Path.cwd()\n",
    "    inp = base / \"Portfolio_analitico_classificado.xlsx\"\n",
    "    out = base / \"Portfolio_analitico_coerencia.xlsx\"\n",
    "    if not inp.exists():\n",
    "        sys.exit(f\"â›” Arquivo nÃ£o encontrado: {inp}\")\n",
    "    return inp, out\n",
    "EXCEL_IN, EXCEL_OUT = get_paths()\n",
    "\n",
    "# 2) Carrega DataFrame e preserva coluna J\n",
    "def carregar_planilha(path):\n",
    "    df = pd.read_excel(path)\n",
    "    wb = load_workbook(path)\n",
    "    ws = wb.active\n",
    "    backup_j = {}\n",
    "    for row in range(2, ws.max_row+1):\n",
    "        cell = ws[f\"J{row}\"]\n",
    "        backup_j[row] = {'value': cell.value, 'fill': cell.fill.copy() if cell.fill and cell.fill.fill_type else None}\n",
    "    wb.close()\n",
    "    return df, backup_j\n",
    "\n",
    "# 3) Calcular coerÃªncia corretamente usando tÃ­tulo vs. abstract\n",
    "def calcular_coerencia(df):\n",
    "    device = 'cuda' if util.torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"â–¶ï¸ Usando device: {device}\\n\")\n",
    "    model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2', device=device)\n",
    "    titles    = df['Title'].fillna('').astype(str).tolist()\n",
    "    abstracts = df['Abstract'].fillna('').astype(str).tolist()\n",
    "    print(\"â³ Gerando embeddings dos tÃ­tulos...\")\n",
    "    emb_titles = model.encode(titles, batch_size=64, show_progress_bar=True, convert_to_tensor=True)\n",
    "    print(\"â³ Gerando embeddings dos resumos...\")\n",
    "    emb_abstracts = model.encode(abstracts, batch_size=64, show_progress_bar=True, convert_to_tensor=True)\n",
    "    print(\"âš¡ Calculando similaridades tÃ­tulo vs. resumo...\")\n",
    "    cosines = util.cos_sim(emb_titles, emb_abstracts).diag().cpu().numpy()\n",
    "    faixas = []\n",
    "    for s in cosines:\n",
    "        if s >= 0.80:   faixas.append('Alta')\n",
    "        elif s >= 0.60: faixas.append('MÃ©dia')\n",
    "        else:           faixas.append('Baixa')\n",
    "    df['CoerÃªncia (Score)']          = cosines\n",
    "    df['ClassificaÃ§Ã£o de CoerÃªncia'] = faixas\n",
    "    return df, cosines, faixas\n",
    "\n",
    "# 4) Gera e salva plots\n",
    "def plot_distribuicoes(scores):\n",
    "    valid = [s for s in scores if not np.isnan(s)]\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.hist(valid, bins=30, edgecolor='black')\n",
    "    plt.title('DistribuiÃ§Ã£o dos Scores de CoerÃªncia')\n",
    "    plt.xlabel('Score de Similaridade')\n",
    "    plt.ylabel('FrequÃªncia')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Histograma_Coerencia.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.boxplot(valid, vert=False)\n",
    "    plt.title('Boxplot dos Scores de CoerÃªncia')\n",
    "    plt.xlabel('Score de Similaridade')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Boxplot_Coerencia.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# 5) Salva novo Excel com backup coluna J\n",
    "def salvar_com_backup(df, backup):\n",
    "    df.to_excel(EXCEL_OUT, index=False)\n",
    "    wb = load_workbook(EXCEL_OUT)\n",
    "    ws = wb.active\n",
    "    for row, info in backup.items():\n",
    "        cell = ws[f\"J{row}\"]\n",
    "        cell.value = info['value']\n",
    "        if info['fill']:\n",
    "            cell.fill = info['fill']\n",
    "    return wb, ws\n",
    "\n",
    "# 6) Destacar 1% piores coerÃªncias\n",
    "def destacar_menores(df, ws):\n",
    "    valid = df[df['CoerÃªncia (Score)'].notnull()]\n",
    "    n = max(1, int(0.01 * len(valid)))\n",
    "    worst = valid.nsmallest(n, 'CoerÃªncia (Score)').index.tolist()\n",
    "    fill = PatternFill(start_color='FFFF00', end_color='FFFF00', fill_type='solid')\n",
    "    for idx in worst:\n",
    "        row = idx + 2\n",
    "        ws[f\"C{row}\"].fill = fill\n",
    "        ws[f\"D{row}\"].fill = fill\n",
    "\n",
    "# 7) FormataÃ§Ã£o geral\n",
    "def formatar(ws):\n",
    "    for row in ws.iter_rows(min_row=1, max_row=ws.max_row,\n",
    "                             min_col=1, max_col=ws.max_column):\n",
    "        for c in row:\n",
    "            c.font = Font(name='Calibri', size=11)\n",
    "            c.alignment = Alignment(horizontal='center', vertical='center')\n",
    "    for c in ws[1]: c.font = Font(bold=True)\n",
    "\n",
    "# 8) RelatÃ³rio final\n",
    "def relatorio_final(df, faixas, start):\n",
    "    total = len(df)\n",
    "    cnt = {k: faixas.count(k) for k in ['Alta','MÃ©dia','Baixa']}\n",
    "    none = total - sum(cnt.values())\n",
    "    now  = datetime.now(SP_TZ)\n",
    "    dur  = str(now - start).split('.')[0]\n",
    "    fmt = lambda x: f\"{x:,d}\".replace(',', '.')\n",
    "    print(\"\\n===== RELATÃ“RIO FINAL =====\")\n",
    "    print(f\"Total analisados       : {fmt(total)}\")\n",
    "    print(f\"Alta CoerÃªncia         : {fmt(cnt['Alta'])} ({cnt['Alta']/total*100:.1f}%)\")\n",
    "    print(f\"MÃ©dia CoerÃªncia        : {fmt(cnt['MÃ©dia'])} ({cnt['MÃ©dia']/total*100:.1f}%)\")\n",
    "    print(f\"Baixa CoerÃªncia        : {fmt(cnt['Baixa'])} ({cnt['Baixa']/total*100:.1f}%)\")\n",
    "    print(f\"Sem dados/Erro         : {fmt(none)} ({none/total*100:.1f}%)\")\n",
    "    print(f\"Tempo de execuÃ§Ã£o: {dur}\")\n",
    "    print(f\"Finalizado em: {now:%Y-%m-%d %H:%M:%S} (FlorianÃ³polis | SC)\")\n",
    "\n",
    "# === MAIN ===\n",
    "if __name__ == '__main__':\n",
    "    df, backup = carregar_planilha(EXCEL_IN)\n",
    "    df, scores, faixas = calcular_coerencia(df)\n",
    "    plot_distribuicoes(scores)\n",
    "    wb, ws = salvar_com_backup(df, backup)\n",
    "    destacar_menores(df, ws)\n",
    "    formatar(ws)\n",
    "    wb.save(EXCEL_OUT)\n",
    "    wb.close()\n",
    "    relatorio_final(df, faixas, data_inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2914053b-d01a-44e9-9693-69b615dbc289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ï¸ InÃ­cio em: 2025-05-04 10:13:47 (FlorianÃ³polis | SC)\n",
      "\n",
      "ğŸ“Š Rodando regressÃ£o OLS (H1a/b)...\n",
      "\n",
      "ğŸ“‹ Tabela de RegressÃ£o OLS (H1a/b):\n",
      "                     VariÃ¡vel  Coeficiente  Erro PadrÃ£o       t  p-valor Sig  IC 95% inferior  IC 95% superior\n",
      "                   Intercepto      -1.3833       0.5001 -2.7659   0.0057  **          -2.3637          -0.4029\n",
      "      AvaliaÃ§Ã£o de desempenho      -0.0035       0.0061 -0.5686   0.5697              -0.0154           0.0085\n",
      " Comportamento Organizacional      -0.0218       0.0051 -4.2418   0.0000 ***          -0.0318          -0.0117\n",
      "                        Custo      -0.0233       0.0047 -4.9910   0.0000 ***          -0.0324          -0.0141\n",
      "            EducaÃ§Ã£o ContÃ¡bil      -0.0021       0.0074 -0.2762   0.7824              -0.0166           0.0125\n",
      "             NÃ£o Classificado      -0.0095       0.0043 -2.2137   0.0269   *          -0.0179          -0.0011\n",
      "                 Outros Temas       0.0027       0.0054  0.4996   0.6174              -0.0079           0.0132\n",
      "Sistema de Controle Gerencial      -0.0206       0.0053 -3.8808   0.0001 ***          -0.0309          -0.0102\n",
      "                          Ano       0.0010       0.0002  4.1473   0.0000 ***           0.0005           0.0015\n",
      "                      Quartil      -0.0099       0.0015 -6.3900   0.0000 ***          -0.0129          -0.0068\n",
      "\n",
      "ğŸ“Š Resumo tÃ©cnico do modelo OLS (sem coef. de paÃ­s):\n",
      "\n",
      "                              OLS Regression Results                              \n",
      "==================================================================================\n",
      "Dep. Variable:     Q(\"CoerÃªncia (Score)\")   R-squared:                       0.071\n",
      "Model:                                OLS   Adj. R-squared:                  0.054\n",
      "Method:                     Least Squares   F-statistic:                     4.176\n",
      "Date:                    Sun, 04 May 2025   Prob (F-statistic):           9.82e-46\n",
      "Time:                            13:13:50   Log-Likelihood:                 5080.6\n",
      "No. Observations:                    6700   AIC:                            -9919.\n",
      "Df Residuals:                        6579   BIC:                            -9095.\n",
      "Df Model:                             120                                         \n",
      "Covariance Type:                nonrobust                                         \n",
      "===================================================================================================================================================\n",
      "                                                                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Intercepto                                                                          -1.3833      0.500     -2.766      0.006      -2.364      -0.403\n",
      "C(Q(\"Grupo TemÃ¡tico\"), Treatment(\"OrÃ§amento\"))[T.AvaliaÃ§Ã£o de desempenho]          -0.0035      0.006     -0.569      0.570      -0.015       0.008\n",
      "C(Q(\"Grupo TemÃ¡tico\"), Treatment(\"OrÃ§amento\"))[T.Comportamento Organizacional]     -0.0218      0.005     -4.242      0.000      -0.032      -0.012\n",
      "C(Q(\"Grupo TemÃ¡tico\"), Treatment(\"OrÃ§amento\"))[T.Custo]                            -0.0233      0.005     -4.991      0.000      -0.032      -0.014\n",
      "C(Q(\"Grupo TemÃ¡tico\"), Treatment(\"OrÃ§amento\"))[T.EducaÃ§Ã£o ContÃ¡bil]                -0.0021      0.007     -0.276      0.782      -0.017       0.013\n",
      "C(Q(\"Grupo TemÃ¡tico\"), Treatment(\"OrÃ§amento\"))[T.NÃ£o Classificado]                 -0.0095      0.004     -2.214      0.027      -0.018      -0.001\n",
      "C(Q(\"Grupo TemÃ¡tico\"), Treatment(\"OrÃ§amento\"))[T.Outros Temas]                      0.0027      0.005      0.500      0.617      -0.008       0.013\n",
      "C(Q(\"Grupo TemÃ¡tico\"), Treatment(\"OrÃ§amento\"))[T.Sistema de Controle Gerencial]    -0.0206      0.005     -3.881      0.000      -0.031      -0.010\n",
      "Ano                                                                           0.0010      0.000      4.147      0.000       0.001       0.001\n",
      "Quartil                                                                 -0.0099      0.002     -6.390      0.000      -0.013      -0.007\n",
      "==============================================================================\n",
      "Omnibus:                      565.483   Durbin-Watson:                   1.958\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              756.090\n",
      "Skew:                          -0.717   Prob(JB):                    6.56e-165\n",
      "Kurtosis:                       3.807   Cond. No.                     1.75e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.75e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Significance levels: * p<0.05, ** p<0.01, *** p<0.001\n",
      "\n",
      "ğŸ“ˆ Gerando heatmap com Top 20 paÃ­ses...\n",
      "ğŸ“Š Gerando estatÃ­sticas por paÃ­s...\n",
      "\n",
      "ğŸ“ Arquivos gerados:\n",
      "  â€¢ H1ab_Regressao_OLS_Resultados.xlsx\n",
      "  â€¢ H1ab_Heatmap_Top20_Paises.png\n",
      "  â€¢ H1ab_Resumo_Por_Pais.xlsx\n",
      "\n",
      "===== RELATÃ“RIO FINAL =====\n",
      "Tempo de execuÃ§Ã£o: 0:00:05\n",
      "Finalizado em: 2025-05-04 10:13:53 (FlorianÃ³polis | SC)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "h1ab_regressao_OLS_orcamento.py\n",
    "\n",
    "Script 6 para:\n",
    "  - Executar anÃ¡lise OLS das hipÃ³teses H1a/H1b com controle por paÃ­s, ano e quartil.\n",
    "  - Exporta:\n",
    "  - Tabela de regressÃ£o (limpa) com significÃ¢ncia no estilo R (*, **, ***).\n",
    "  - Heatmap dos Top 20 paÃ­ses (CoerÃªncia por PaÃ­s e Ano).\n",
    "  - EstatÃ­sticas descritivas por paÃ­s.\n",
    "\n",
    "Inclui print tÃ©cnico do modelo sem coeficientes de paÃ­s e com nomes legÃ­veis.\n",
    "\n",
    "USO NO CLUSTER UFSC (JupyterLab ou SLURM):\n",
    "  â€¢ Instale dependÃªncias: pip install pandas statsmodels openpyxl seaborn matplotlib\n",
    "  â€¢ No cluster: module load python/3.10 pandas statsmodels openpyxl seaborn matplotlib\n",
    "  â€¢ Execute: python h1ab_regressao_OLS_orcamento.py\n",
    "  â€¢ Arquivo \"Portfolio_analitico_coerencia.xlsx\" deve estar no diretÃ³rio atual.\n",
    "\n",
    "DEPENDÃŠNCIAS:\n",
    "  pandas, statsmodels, openpyxl, seaborn, matplotlib\n",
    "\n",
    "Autor: G.O., Renato | NEIMAC | PPGC | UFSC | Mestrado\n",
    "Contribuidores: [Adicione seu nome, se aplicÃ¡vel]\n",
    "LicenÃ§a: MIT (CiÃªncia Aberta - Open Science Framework)\n",
    "Data: 02/05/2025\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import re\n",
    "\n",
    "# FunÃ§Ã£o para instalar pacotes, se necessÃ¡rio\n",
    "def instalar(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "for pkg in (\"pandas\", \"statsmodels\", \"openpyxl\", \"seaborn\", \"matplotlib\"):\n",
    "    try:\n",
    "        __import__(pkg.replace('-', '_'))\n",
    "    except ImportError:\n",
    "        print(f\"âš™ï¸ Instalando {pkg}...\")\n",
    "        instalar(pkg)\n",
    "\n",
    "# FunÃ§Ã£o para marcar significÃ¢ncia no estilo R\n",
    "def marcar_sig(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# FunÃ§Ã£o para limpar nomes das variÃ¡veis\n",
    "def limpar_nome_variavel(v):\n",
    "    if 'Grupo TemÃ¡tico' in v:\n",
    "        if 'T.' in v:\n",
    "            return v.split('T.')[1].strip(']')\n",
    "        else:\n",
    "            return 'OrÃ§amento'  # ALTERAÃ‡ÃƒO: Mudei de 'AvaliaÃ§Ã£o de Desempenho' pra 'OrÃ§amento'\n",
    "    elif v == 'Intercept':\n",
    "        return 'Intercepto'\n",
    "    elif v == 'Q(\"Year\")':\n",
    "        return 'Ano'\n",
    "    elif v == 'Q(\"Best Quartile\")':\n",
    "        return 'Quartil'\n",
    "    return v\n",
    "\n",
    "# InÃ­cio\n",
    "SC_TZ = ZoneInfo(\"America/Sao_Paulo\")\n",
    "inicio = datetime.now(SC_TZ)\n",
    "print(f\"â–¶ï¸ InÃ­cio em: {inicio:%Y-%m-%d %H:%M:%S} (FlorianÃ³polis | SC)\\n\")\n",
    "\n",
    "# Leitura do arquivo\n",
    "arquivo = Path(\"Portfolio_analitico_coerencia.xlsx\")\n",
    "if not arquivo.exists():\n",
    "    sys.exit(f\"â›” Arquivo nÃ£o encontrado: {arquivo}\")\n",
    "df = pd.read_excel(arquivo)\n",
    "\n",
    "# PreparaÃ§Ã£o dos dados\n",
    "df = df[['CoerÃªncia (Score)', 'Grupo TemÃ¡tico', 'Year', 'PaÃ­s', 'Best Quartile']].dropna()\n",
    "df = df[df['Best Quartile'].str.startswith('Q')]\n",
    "df['Best Quartile'] = df['Best Quartile'].str.replace('Q', '').astype(int)\n",
    "df = df[df['PaÃ­s'].str.isalpha() & ~df['PaÃ­s'].isin(['NÃ£o Identificado'])]\n",
    "\n",
    "# RegressÃ£o OLS\n",
    "print(\"ğŸ“Š Rodando regressÃ£o OLS (H1a/b)...\")\n",
    "# ALTERAÃ‡ÃƒO: Adicionei Treatment(\"OrÃ§amento\") pra definir OrÃ§amento como referÃªncia\n",
    "formula = 'Q(\"CoerÃªncia (Score)\") ~ C(Q(\"Grupo TemÃ¡tico\"), Treatment(\"OrÃ§amento\")) + Q(\"Year\") + C(Q(\"PaÃ­s\")) + Q(\"Best Quartile\")'\n",
    "modelo = smf.ols(formula=formula, data=df).fit()\n",
    "\n",
    "# Tabela de saÃ­da formatada no estilo R\n",
    "tabela = modelo.summary2().tables[1].reset_index()\n",
    "# Removemos o filtro para incluir todas as variÃ¡veis (nÃ£o apenas Grupo TemÃ¡tico)\n",
    "tabela = tabela[~tabela['index'].str.contains('PaÃ­s')].copy()  # Exclui apenas os coeficientes de PaÃ­s\n",
    "tabela.columns = ['VariÃ¡vel', 'Coeficiente', 'Erro PadrÃ£o', 't', 'p-valor', 'IC 95% inferior', 'IC 95% superior']\n",
    "tabela['VariÃ¡vel'] = tabela['VariÃ¡vel'].apply(limpar_nome_variavel)\n",
    "tabela['Sig'] = tabela['p-valor'].apply(marcar_sig)\n",
    "tabela = tabela[['VariÃ¡vel', 'Coeficiente', 'Erro PadrÃ£o', 't', 'p-valor', 'Sig', 'IC 95% inferior', 'IC 95% superior']]\n",
    "tabela = tabela.round(4)\n",
    "tabela.to_excel(\"H1ab_Regressao_OLS_Resultados.xlsx\", index=False)\n",
    "\n",
    "# Imprimir a tabela no console\n",
    "print(\"\\nğŸ“‹ Tabela de RegressÃ£o OLS (H1a/b):\")\n",
    "print(tabela.to_string(index=False))\n",
    "\n",
    "# Resumo tÃ©cnico limpo (sem coeficientes de paÃ­s e com nomes legÃ­veis)\n",
    "print(\"\\nğŸ“Š Resumo tÃ©cnico do modelo OLS (sem coef. de paÃ­s):\\n\")\n",
    "resumo_str = modelo.summary().as_text()\n",
    "resumo_limpo = re.sub(\n",
    "    r'C\\(Q\\(\"PaÃ­s\"\\)\\)\\[T\\..+?\\]\\s+[-\\d\\.e\\+]+\\s+[-\\d\\.e\\+]+\\s+[-\\d\\.e\\+]+\\s+[-\\d\\.e\\+]+\\s+[-\\d\\.e\\+]+\\s+[-\\d\\.e\\+]+\\n',\n",
    "    '', resumo_str)\n",
    "\n",
    "# Substituir nomes tÃ©cnicos por nomes legÃ­veis\n",
    "substituir_variaveis = {\n",
    "    'C\\\\(Q\\\\(\"Grupo TemÃ¡tico\"\\\\)\\\\)\\\\[T.Comportamento Organizacional\\\\]': \"Comportamento Organizacional\",\n",
    "    'C\\\\(Q\\\\(\"Grupo TemÃ¡tico\"\\\\)\\\\)\\\\[T.Custo\\\\]': \"Custo\",\n",
    "    'C\\\\(Q\\\\(\"Grupo TemÃ¡tico\"\\\\)\\\\)\\\\[T.EducaÃ§Ã£o ContÃ¡bil\\\\]': \"EducaÃ§Ã£o ContÃ¡bil\",\n",
    "    'C\\\\(Q\\\\(\"Grupo TemÃ¡tico\"\\\\)\\\\)\\\\[T.NÃ£o Classificado\\\\]': \"NÃ£o Classificado\",\n",
    "    'C\\\\(Q\\\\(\"Grupo TemÃ¡tico\"\\\\)\\\\)\\\\[T.OrÃ§amento\\\\]': \"OrÃ§amento\",\n",
    "    'C\\\\(Q\\\\(\"Grupo TemÃ¡tico\"\\\\)\\\\)\\\\[T.Outros Temas\\\\]': \"Outros Temas\",\n",
    "    'C\\\\(Q\\\\(\"Grupo TemÃ¡tico\"\\\\)\\\\)\\\\[T.Sistema de Controle Gerencial\\\\]': \"Sistema de Controle Gerencial\",\n",
    "    'Q\\\\(\"Year\"\\\\)': \"Ano\",\n",
    "    'Q\\\\(\"Best Quartile\"\\\\)': \"Quartil\",\n",
    "    'Intercept': 'Intercepto'\n",
    "}\n",
    "for padrao, nome_limpo in substituir_variaveis.items():\n",
    "    resumo_limpo = re.sub(padrao, nome_limpo, resumo_limpo)\n",
    "\n",
    "# Adicionar nota sobre significÃ¢ncia\n",
    "resumo_limpo += \"\\nSignificance levels: * p<0.05, ** p<0.01, *** p<0.001\"\n",
    "print(resumo_limpo)\n",
    "\n",
    "# Heatmap dos Top 20 paÃ­ses\n",
    "print(\"\\nğŸ“ˆ Gerando heatmap com Top 20 paÃ­ses...\")\n",
    "df_heat = df[['PaÃ­s', 'Year', 'CoerÃªncia (Score)']].dropna()\n",
    "df_heat = df_heat[df_heat['Year'].between(1995, 2025)]\n",
    "top20 = df_heat['PaÃ­s'].value_counts().nlargest(20).index.tolist()\n",
    "df_heat = df_heat[df_heat['PaÃ­s'].isin(top20)]\n",
    "pivot = df_heat.groupby(['PaÃ­s', 'Year'])['CoerÃªncia (Score)'].mean().reset_index().pivot(\n",
    "    index='PaÃ­s', columns='Year', values='CoerÃªncia (Score)'\n",
    ")\n",
    "pivot = pivot.reindex(columns=range(1995, 2026))\n",
    "plt.figure(figsize=(18, 10))\n",
    "sns.heatmap(pivot, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", linewidths=0.5, linecolor='gray')\n",
    "plt.title(\"MÃ©dia do Score de CoerÃªncia por PaÃ­s Ã— Ano (Top 20 PaÃ­ses)\")\n",
    "plt.xlabel(\"Ano\")\n",
    "plt.ylabel(\"PaÃ­s\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"H1ab_Heatmap_Top20_Paises.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# EstatÃ­sticas descritivas por paÃ­s\n",
    "print(\"ğŸ“Š Gerando estatÃ­sticas por paÃ­s...\")\n",
    "agg = df.groupby('PaÃ­s')['CoerÃªncia (Score)'].agg(['count', 'mean', 'std', 'median', 'min', 'max']).round(3)\n",
    "agg.columns = ['N Artigos', 'MÃ©dia', 'Desvio PadrÃ£o', 'Mediana', 'MÃ­nimo', 'MÃ¡ximo']\n",
    "agg = agg.sort_values('MÃ©dia', ascending=False)\n",
    "agg.to_excel(\"H1ab_Resumo_Por_Pais.xlsx\")\n",
    "\n",
    "# RelatÃ³rio final\n",
    "fim = datetime.now(SC_TZ)\n",
    "dur = str(fim - inicio).split('.')[0]\n",
    "print(\"\\nğŸ“ Arquivos gerados:\")\n",
    "print(\"  â€¢ H1ab_Regressao_OLS_Resultados.xlsx\")\n",
    "print(\"  â€¢ H1ab_Heatmap_Top20_Paises.png\")\n",
    "print(\"  â€¢ H1ab_Resumo_Por_Pais.xlsx\")\n",
    "print(\"\\n===== RELATÃ“RIO FINAL =====\")\n",
    "print(f\"Tempo de execuÃ§Ã£o: {dur}\")\n",
    "print(f\"Finalizado em: {fim:%Y-%m-%d %H:%M:%S} (FlorianÃ³polis | SC)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0221539f-c0c0-4076-94ed-d098050090e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ï¸ InÃ­cio em: 2025-05-04 14:06:06 (FlorianÃ³polis | SC)\n",
      "\n",
      "ğŸ“Š Rodando regressÃ£o OLS (H2a/b)...\n",
      "ğŸ” VariÃ¡veis antes da ordenaÃ§Ã£o: ['Intercepto', '(Q1-Q2)', 'Ano']\n",
      "\n",
      "ğŸ“‹ Tabela de RegressÃ£o OLS (H2a/b):\n",
      "Dependente: CoerÃªncia (Score)\n",
      "Nota: (Q3-Q4) Ã© a referÃªncia (coeficiente 0).\n",
      "  VariÃ¡vel  Coeficiente  Erro PadrÃ£o       t  p-valor Sig  IC 95% inferior  IC 95% superior\n",
      "Intercepto      -1.2666       0.4988 -2.5394   0.0111   *          -2.2444          -0.2889\n",
      "       Ano       0.0009       0.0002  3.7948   0.0001 ***           0.0004           0.0014\n",
      "   (Q1-Q2)       0.0207       0.0035  5.9960   0.0000 ***           0.0140           0.0275\n",
      "   (Q3-Q4)       0.0000       0.0000  0.0000   1.0000               0.0000           0.0000\n",
      "\n",
      "ğŸ“Š Resumo tÃ©cnico do modelo OLS (sem coef. de paÃ­s):\n",
      "\n",
      "                              OLS Regression Results                              \n",
      "==================================================================================\n",
      "Dep. Variable: CoerÃªncia (Score)\n",
      "Model:                                OLS   Adj. R-squared:                  0.047\n",
      "Method:                     Least Squares   F-statistic:                     3.932\n",
      "Date:                    Sun, 04 May 2025   Prob (F-statistic):           4.44e-39\n",
      "Time:                            17:06:08   Log-Likelihood:                 5053.4\n",
      "No. Observations:                    6700   AIC:                            -9879.\n",
      "Df Residuals:                        6586   BIC:                            -9102.\n",
      "Df Model:                             113                                         \n",
      "Covariance Type:                nonrobust                                         \n",
      "=================================================================================================\n",
      "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Intercepto                        -1.2666      0.499     -2.539      0.011      -2.244      -0.289\n",
      "(Q1-Q2)         0.0207      0.003      5.996      0.000       0.014       0.028\n",
      "Ano                         0.0009      0.000      3.795      0.000       0.000       0.001\n",
      "==============================================================================\n",
      "Omnibus:                      579.289   Durbin-Watson:                   1.954\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              777.266\n",
      "Skew:                          -0.729   Prob(JB):                    1.66e-169\n",
      "Kurtosis:                       3.812   Cond. No.                     1.75e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.75e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Significance levels: * p<0.05, ** p<0.01, *** p<0.001\n",
      "\n",
      "ğŸ“ˆ Gerando heatmap com Top 20 paÃ­ses...\n",
      "ğŸ“Š Gerando estatÃ­sticas por paÃ­s...\n",
      "\n",
      "ğŸ“ Arquivos gerados:\n",
      "  â€¢ H2ab_Regressao_OLS_Resultados.xlsx\n",
      "  â€¢ H2ab_Heatmap_Top20_Paises.png\n",
      "  â€¢ H2ab_Resumo_Por_Pais.xlsx\n",
      "\n",
      "===== RELATÃ“RIO FINAL =====\n",
      "Tempo de execuÃ§Ã£o: 0:00:03\n",
      "Finalizado em: 2025-05-04 14:06:10 (FlorianÃ³polis | SC)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "h2ab_regressao_OLS_analise_completa.py\n",
    "\n",
    "Script 7 para:\n",
    "  - Executar anÃ¡lise OLS das hipÃ³teses H2a/H2b, investigando a relaÃ§Ã£o entre o impacto\n",
    "    dos periÃ³dicos ((Q1-Q2) vs. (Q3-Q4)) e a coerÃªncia comunicacional, controlando por\n",
    "    paÃ­s e ano. Exporta:\n",
    "  - Tabela de regressÃ£o com significÃ¢ncia no estilo R (*, **, ***).\n",
    "  - Heatmap dos Top 20 paÃ­ses (CoerÃªncia por Ano).\n",
    "  - EstatÃ­sticas descritivas por paÃ­s.\n",
    "\n",
    "USO NO CLUSTER UFSC (JupyterLab ou SLURM):\n",
    "  â€¢ Instale dependÃªncias: pip install pandas statsmodels openpyxl seaborn matplotlib\n",
    "  â€¢ No cluster: module load python/3.10 pandas statsmodels openpyxl seaborn matplotlib\n",
    "  â€¢ Execute: python h2ab_regressao_OLS_analise_completa.py\n",
    "  â€¢ Arquivo \"Portfolio_analitico_coerencia.xlsx\" deve estar no diretÃ³rio atual.\n",
    "\n",
    "DEPENDÃŠNCIAS:\n",
    "  pandas, statsmodels, openpyxl, seaborn, matplotlib\n",
    "\n",
    "Autor: G.O., Renato | NEIMAC | PPGC | UFSC | Mestrado\n",
    "LicenÃ§a: MIT (CiÃªncia Aberta - Open Science Framework)\n",
    "Data: 02/05/2025\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import re\n",
    "\n",
    "# FunÃ§Ã£o para instalar pacotes, se necessÃ¡rio\n",
    "def instalar(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "for pkg in (\"pandas\", \"statsmodels\", \"openpyxl\", \"seaborn\", \"matplotlib\"):\n",
    "    try:\n",
    "        __import__(pkg.replace('-', '_'))\n",
    "    except ImportError:\n",
    "        print(f\"âš™ï¸ Instalando {pkg}...\")\n",
    "        instalar(pkg)\n",
    "\n",
    "# FunÃ§Ã£o para marcar significÃ¢ncia no estilo R\n",
    "def marcar_sig(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# FunÃ§Ã£o para limpar nomes das variÃ¡veis\n",
    "def limpar_nome_variavel(v):\n",
    "    if v == 'Intercept':\n",
    "        return 'Intercepto'\n",
    "    elif v == 'Q(\"Year\")':\n",
    "        return 'Ano'\n",
    "    elif v == 'C(Q(\"Quartil_Alto\"))[T.1]':\n",
    "        return '(Q1-Q2)'\n",
    "    return v\n",
    "\n",
    "# FunÃ§Ã£o para extrair o nÃºmero do quartil para ordenaÃ§Ã£o\n",
    "def extrair_quartil(v):\n",
    "    if v == 'Intercepto':\n",
    "        return -2  # Intercepto primeiro\n",
    "    elif v == 'Ano':\n",
    "        return -1  # Ano depois do Intercepto\n",
    "    elif v == '(Q1-Q2)':\n",
    "        return 1  # (Q1-Q2) primeiro\n",
    "    elif v == '(Q3-Q4)':\n",
    "        return 2  # (Q3-Q4) depois\n",
    "    return 0  # Outros casos (nÃ£o deve ocorrer)\n",
    "\n",
    "# InÃ­cio\n",
    "SC_TZ = ZoneInfo(\"America/Sao_Paulo\")\n",
    "inicio = datetime.now(SC_TZ)\n",
    "print(f\"â–¶ï¸ InÃ­cio em: {inicio:%Y-%m-%d %H:%M:%S} (FlorianÃ³polis | SC)\\n\")\n",
    "\n",
    "# Leitura do arquivo\n",
    "arquivo = Path(\"Portfolio_analitico_coerencia.xlsx\")\n",
    "if not arquivo.exists():\n",
    "    sys.exit(f\"â›” Arquivo nÃ£o encontrado: {arquivo}\")\n",
    "df = pd.read_excel(arquivo)\n",
    "\n",
    "# PreparaÃ§Ã£o dos dados\n",
    "df = df[['CoerÃªncia (Score)', 'Best Quartile', 'Year', 'PaÃ­s']].dropna()\n",
    "df = df[df['Best Quartile'].str.startswith('Q')]\n",
    "df['Best Quartile'] = df['Best Quartile'].str.replace('Q', '').astype(int)\n",
    "df = df[df['PaÃ­s'].str.isalpha() & ~df['PaÃ­s'].isin(['NÃ£o Identificado'])]\n",
    "\n",
    "# Criar dummy para Quartil Alto (Q1-Q2 = 1, Q3-Q4 = 0)\n",
    "df['Quartil_Alto'] = (df['Best Quartile'] <= 2).astype(int)\n",
    "\n",
    "# RegressÃ£o OLS\n",
    "print(\"ğŸ“Š Rodando regressÃ£o OLS (H2a/b)...\")\n",
    "formula = 'Q(\"CoerÃªncia (Score)\") ~ C(Q(\"Quartil_Alto\")) + Q(\"Year\") + C(Q(\"PaÃ­s\"))'\n",
    "modelo = smf.ols(formula=formula, data=df).fit()\n",
    "\n",
    "# Tabela de saÃ­da formatada no estilo R\n",
    "tabela = modelo.summary2().tables[1].reset_index()\n",
    "tabela = tabela[~tabela['index'].str.contains('PaÃ­s')].copy()  # Exclui apenas os coeficientes de PaÃ­s\n",
    "tabela.columns = ['VariÃ¡vel', 'Coeficiente', 'Erro PadrÃ£o', 't', 'p-valor', 'IC 95% inferior', 'IC 95% superior']\n",
    "tabela['VariÃ¡vel'] = tabela['VariÃ¡vel'].apply(limpar_nome_variavel)\n",
    "print(\"ğŸ” VariÃ¡veis antes da ordenaÃ§Ã£o:\", tabela['VariÃ¡vel'].tolist())  # Log para depuraÃ§Ã£o\n",
    "tabela['Sig'] = tabela['p-valor'].apply(marcar_sig)\n",
    "# Adicionar linha de referÃªncia (Q3-Q4) manualmente\n",
    "ref_row = pd.DataFrame({\n",
    "    'VariÃ¡vel': ['(Q3-Q4)'],\n",
    "    'Coeficiente': [0.0000],\n",
    "    'Erro PadrÃ£o': [0.0000],\n",
    "    't': [0.0000],\n",
    "    'p-valor': [1.0000],\n",
    "    'IC 95% inferior': [0.0000],\n",
    "    'IC 95% superior': [0.0000],\n",
    "    'Sig': ['']\n",
    "})\n",
    "tabela = pd.concat([tabela, ref_row], ignore_index=True)\n",
    "# Reordenar para listar Intercepto, Ano, (Q1-Q2), (Q3-Q4)\n",
    "tabela['Ordem'] = tabela['VariÃ¡vel'].apply(extrair_quartil)\n",
    "tabela = tabela.sort_values('Ordem')\n",
    "tabela = tabela[['VariÃ¡vel', 'Coeficiente', 'Erro PadrÃ£o', 't', 'p-valor', 'Sig', 'IC 95% inferior', 'IC 95% superior']]\n",
    "tabela = tabela.round(4)\n",
    "tabela.to_excel(\"H2ab_Regressao_OLS_Resultados.xlsx\", index=False)\n",
    "\n",
    "# Imprimir a tabela no console\n",
    "print(\"\\nğŸ“‹ Tabela de RegressÃ£o OLS (H2a/b):\")\n",
    "print(\"Dependente: CoerÃªncia (Score)\")\n",
    "print(\"Nota: (Q3-Q4) Ã© a referÃªncia (coeficiente 0).\")\n",
    "print(tabela.to_string(index=False))\n",
    "\n",
    "# Resumo tÃ©cnico limpo (sem coeficientes de paÃ­s e com nomes legÃ­veis)\n",
    "print(\"\\nğŸ“Š Resumo tÃ©cnico do modelo OLS (sem coef. de paÃ­s):\\n\")\n",
    "resumo_str = modelo.summary().as_text()\n",
    "resumo_limpo = re.sub(\n",
    "    r'C\\(Q\\(\"PaÃ­s\"\\)\\)\\[T\\..+?\\]\\s+[-\\d\\.e\\+]+\\s+[-\\d\\.e\\+]+\\s+[-\\d\\.e\\+]+\\s+[-\\d\\.e\\+]+\\s+[-\\d\\.e\\+]+\\s+[-\\d\\.e\\+]+\\n',\n",
    "    '', resumo_str)\n",
    "substituir_variaveis = {\n",
    "    r'C\\(Q\\(\"Quartil_Alto\"\\)\\)\\[T\\.1\\]': \"(Q1-Q2)\",\n",
    "    r'Q\\(\"Year\"\\)': \"Ano\",\n",
    "    r'Intercept': 'Intercepto'\n",
    "}\n",
    "for padrao, nome_limpo in substituir_variaveis.items():\n",
    "    resumo_limpo = re.sub(padrao, nome_limpo, resumo_limpo)\n",
    "resumo_limpo = re.sub(r'Dep\\. Variable:.*\\n', 'Dep. Variable: CoerÃªncia (Score)\\n', resumo_limpo)\n",
    "resumo_limpo += \"\\nSignificance levels: * p<0.05, ** p<0.01, *** p<0.001\"\n",
    "print(resumo_limpo)\n",
    "\n",
    "# Heatmap dos Top 20 paÃ­ses\n",
    "print(\"\\nğŸ“ˆ Gerando heatmap com Top 20 paÃ­ses...\")\n",
    "df_heat = df[['PaÃ­s', 'Year', 'CoerÃªncia (Score)']].dropna()\n",
    "df_heat = df_heat[df_heat['Year'].between(1995, 2025)]\n",
    "top20 = df_heat['PaÃ­s'].value_counts().nlargest(20).index.tolist()\n",
    "df_heat = df_heat[df_heat['PaÃ­s'].isin(top20)]\n",
    "pivot = df_heat.groupby(['PaÃ­s', 'Year'])['CoerÃªncia (Score)'].mean().reset_index().pivot(\n",
    "    index='PaÃ­s', columns='Year', values='CoerÃªncia (Score)'\n",
    ")\n",
    "pivot = pivot.reindex(columns=range(1995, 2026))\n",
    "plt.figure(figsize=(18, 10))\n",
    "sns.heatmap(pivot, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", linewidths=0.5, linecolor='gray')\n",
    "plt.title(\"MÃ©dia do Score de CoerÃªncia por PaÃ­s Ã— Ano (Top 20 PaÃ­ses)\")\n",
    "plt.xlabel(\"Ano\")\n",
    "plt.ylabel(\"PaÃ­s\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"H2ab_Heatmap_Top20_Paises.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# EstatÃ­sticas descritivas por paÃ­s\n",
    "print(\"ğŸ“Š Gerando estatÃ­sticas por paÃ­s...\")\n",
    "agg = df.groupby('PaÃ­s')['CoerÃªncia (Score)'].agg(['count', 'mean', 'std', 'median', 'min', 'max']).round(3)\n",
    "agg.columns = ['N Artigos', 'MÃ©dia', 'Desvio PadrÃ£o', 'Mediana', 'MÃ­nimo', 'MÃ¡ximo']\n",
    "agg = agg.sort_values('MÃ©dia', ascending=False)\n",
    "agg.to_excel(\"H2ab_Resumo_Por_Pais.xlsx\")\n",
    "\n",
    "# RelatÃ³rio final\n",
    "fim = datetime.now(SC_TZ)\n",
    "dur = str(fim - inicio).split('.')[0]\n",
    "print(\"\\nğŸ“ Arquivos gerados:\")\n",
    "print(\"  â€¢ H2ab_Regressao_OLS_Resultados.xlsx\")\n",
    "print(\"  â€¢ H2ab_Heatmap_Top20_Paises.png\")\n",
    "print(\"  â€¢ H2ab_Resumo_Por_Pais.xlsx\")\n",
    "print(\"\\n===== RELATÃ“RIO FINAL =====\")\n",
    "print(f\"Tempo de execuÃ§Ã£o: {dur}\")\n",
    "print(f\"Finalizado em: {fim:%Y-%m-%d %H:%M:%S} (FlorianÃ³polis | SC)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ac3bbd3-ecd2-4f38-872a-8dd5bca03d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ï¸ InÃ­cio em: 2025-05-04 15:55:02 (FlorianÃ³polis | SC)\n",
      "\n",
      "ğŸ“Š Preparando dados...\n",
      "ğŸ” Tratando valores extremos em Cited by...\n",
      "ğŸ” Verificando dados...\n",
      "  â€¢ ObservaÃ§Ãµes: 13614\n",
      "  â€¢ Zeros em Cited by: 15.5%\n",
      "  â€¢ Categorias em ClassificaÃ§Ã£o de CoerÃªncia: {'MÃ©dia': 8573, 'Baixa': 3862, 'Alta': 1179}\n",
      "  â€¢ Categorias em Best Quartile: {'Q1': 4721, 'NE': 3101, 'Q2': 3090, 'Q3': 1621, 'Q4': 1081}\n",
      "ğŸ“Š Rodando regressÃ£o OLS (H3a/b)...\n",
      "\n",
      "ğŸ“‹ Tabela de regressÃ£o OLS (H3a/b):\n",
      "ğŸ” Colunas em tabela_ols: ['index', 'Coef.', 'Std.Err.', 'z', 'P>|z|', '[0.025', '0.975]', 'VariÃ¡vel']\n",
      "Dependente: log(1 + Cited by) (OLS)\n",
      "                             VariÃ¡vel  Coeficiente  Erro PadrÃ£o      z/t  p-valor Sig  IC 95% inferior  IC 95% superior\n",
      "              Alta (coerÃªncia â‰¥ 0,80)       0.0000       0.0000   0.0000    1.000               0.0000           0.0000\n",
      "             Baixa (coerÃªncia < 0,60)      -0.2019       0.0382  -5.2847    0.000 ***          -0.2768          -0.1270\n",
      "MÃ©dia (coerÃªncia entre 0,60 e < 0,80)      -0.0599       0.0359  -1.6698    0.095              -0.1302           0.0104\n",
      "                           Intercepto     157.1231       3.3138  47.4152    0.000 ***         150.6282         163.6180\n",
      "                                  Ano      -0.0770       0.0016 -46.9122    0.000 ***          -0.0802          -0.0738\n",
      "                           Quartil Q1       1.0779       0.0285  37.7838    0.000 ***           1.0220           1.1339\n",
      "                           Quartil Q2       0.2433       0.0301   8.0831    0.000 ***           0.1843           0.3023\n",
      "                           Quartil Q3      -0.1409       0.0344  -4.0997    0.000 ***          -0.2083          -0.0736\n",
      "                           Quartil Q4      -0.6576       0.0347 -18.9552    0.000 ***          -0.7256          -0.5896\n",
      "\n",
      "ğŸ“Š Resumo tÃ©cnico do modelo:\n",
      "\n",
      "Modelo OLS:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable: log(1 + Cited by)\n",
      "Model:                            OLS   Adj. R-squared:                  0.362\n",
      "Method:                 Least Squares   F-statistic:                     1212.\n",
      "Date:                Sun, 04 May 2025   Prob (F-statistic):               0.00\n",
      "Time:                        18:55:04   Log-Likelihood:                -20973.\n",
      "No. Observations:               13614   AIC:                         4.196e+04\n",
      "Df Residuals:                   13606   BIC:                         4.202e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:                  HC3                                         \n",
      "===============================================================================================================\n",
      "                                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "Intercepto                                     157.1231      3.314     47.415      0.000     150.628     163.618\n",
      "Baixa    -0.2019      0.038     -5.285      0.000      -0.277      -0.127\n",
      "MÃ©dia    -0.0599      0.036     -1.670      0.095      -0.130       0.010\n",
      "Quartil Q1                     1.0779      0.029     37.784      0.000       1.022       1.134\n",
      "Quartil Q2                     0.2433      0.030      8.083      0.000       0.184       0.302\n",
      "Quartil Q3                    -0.1409      0.034     -4.100      0.000      -0.208      -0.074\n",
      "Quartil Q4                    -0.6576      0.035    -18.955      0.000      -0.726      -0.590\n",
      "Ano                                      -0.0770      0.002    -46.912      0.000      -0.080      -0.074\n",
      "==============================================================================\n",
      "Omnibus:                       96.084   Durbin-Watson:                   1.592\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               72.628\n",
      "Skew:                          -0.085   Prob(JB):                     1.69e-16\n",
      "Kurtosis:                       2.685   Cond. No.                     6.00e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
      "[2] The condition number is large,  6e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Significance levels: * p<0.05, ** p<0.01, *** p<0.001\n",
      "\n",
      "ğŸ“Š Gerando estatÃ­sticas por ClassificaÃ§Ã£o de CoerÃªncia...\n",
      "\n",
      "ğŸ“ Arquivos gerados:\n",
      "  â€¢ H3ab_Regressao_Comparativa_Resultados.xlsx\n",
      "  â€¢ H3ab_Resumo_Por_Coerencia.xlsx\n",
      "\n",
      "===== RELATÃ“RIO FINAL =====\n",
      "Tempo de execuÃ§Ã£o: 0:00:01\n",
      "Finalizado em: 2025-05-04 15:55:04 (FlorianÃ³polis | SC)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "h3ab_regressao_OLS_analise_completa_corrigido.py\n",
    "\n",
    "Script 8 para:\n",
    "  - Executar anÃ¡lise de RegressÃ£o OLS para as hipÃ³teses H3a/H3b, investigando a relaÃ§Ã£o\n",
    "    entre a coerÃªncia comunicacional (ClassificaÃ§Ã£o de CoerÃªncia: Alta vs. MÃ©dia/Baixa)\n",
    "    e o nÃºmero de citaÃ§Ãµes (log(1 + Cited by)), controlando por Best Quartile e Ano.\n",
    "    Exporta:\n",
    "  - Tabela de regressÃ£o OLS com significÃ¢ncia no estilo R (*, **, ***), com variÃ¡veis de controle separadas e descriÃ§Ãµes detalhadas.\n",
    "  - EstatÃ­sticas descritivas por ClassificaÃ§Ã£o de CoerÃªncia.\n",
    "  - Resumo tÃ©cnico do modelo.\n",
    "\n",
    "USO NO CLUSTER UFSC (JupyterLab ou SLURM):\n",
    "  â€¢ Instale dependÃªncias: pip install pandas statsmodels openpyxl numpy scipy\n",
    "  â€¢ No cluster: module load python/3.10 pandas statsmodels openpyxl numpy scipy\n",
    "  â€¢ Execute: python h3ab_regressao_OLS_analise_completa_corrigido.py\n",
    "  â€¢ Arquivo \"Portfolio_analitico_coerencia.xlsx\" deve estar no diretÃ³rio atual.\n",
    "\n",
    "DEPENDÃŠNCIAS:\n",
    "  pandas, statsmodels, openpyxl, numpy, scipy\n",
    "\n",
    "Autor: G.O., Renato | NEIMAC | PPGC | UFSC | Mestrado\n",
    "LicenÃ§a: MIT (CiÃªncia Aberta - Open Science Framework)\n",
    "Data: 03/05/2025\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "# FunÃ§Ã£o para instalar pacotes, se necessÃ¡rio\n",
    "def instalar(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "for pkg in (\"pandas\", \"statsmodels\", \"openpyxl\", \"numpy\", \"scipy\"):\n",
    "    try:\n",
    "        __import__(pkg.replace('-', '_'))\n",
    "    except ImportError:\n",
    "        print(f\"âš™ï¸ Instalando {pkg}...\")\n",
    "        instalar(pkg)\n",
    "\n",
    "# FunÃ§Ã£o para marcar significÃ¢ncia no estilo R\n",
    "def marcar_sig(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# FunÃ§Ã£o para limpar nomes das variÃ¡veis e adicionar descriÃ§Ãµes\n",
    "def limpar_nome_variavel_com_descricao(v):\n",
    "    if v == 'Intercept':\n",
    "        return 'Intercepto'\n",
    "    elif v == 'Q(\"Year\")':\n",
    "        return 'Ano'\n",
    "    elif v.startswith('C(Q(\"ClassificaÃ§Ã£o de CoerÃªncia\"))[T.'):\n",
    "        categoria = v.split('T.')[1].split(']')[0]\n",
    "        if categoria == 'Alta':\n",
    "            return 'Alta (coerÃªncia â‰¥ 0,80)'\n",
    "        elif categoria == 'Baixa':\n",
    "            return 'Baixa (coerÃªncia < 0,60)'\n",
    "        elif categoria == 'MÃ©dia':\n",
    "            return 'MÃ©dia (coerÃªncia entre 0,60 e < 0,80)'\n",
    "    elif v.startswith('C(Q(\"Best Quartile\"))[T.'):\n",
    "        return f\"Quartil {v.split('T.')[1].split(']')[0]}\"\n",
    "    return v\n",
    "\n",
    "# FunÃ§Ã£o para extrair ordem das variÃ¡veis e identificar se Ã© de controle\n",
    "def extrair_ordem_variavel(v):\n",
    "    if v == 'Intercepto':\n",
    "        return -2, True\n",
    "    elif v == 'Ano':\n",
    "        return -1, True\n",
    "    elif v.startswith('Alta'):\n",
    "        return 1, False\n",
    "    elif v.startswith('Baixa'):\n",
    "        return 2, False\n",
    "    elif v.startswith('MÃ©dia'):\n",
    "        return 3, False\n",
    "    elif v.startswith('Quartil'):\n",
    "        if v == 'Quartil NE':\n",
    "            return 4, True\n",
    "        try:\n",
    "            return 4 + int(v.split(' ')[1][1:]), True  # Extrai nÃºmero de \"Q1\", \"Q2\", etc.\n",
    "        except (ValueError, IndexError):\n",
    "            return 4, True  # Trata valores nÃ£o numÃ©ricos como NE\n",
    "    return 100, False\n",
    "\n",
    "# InÃ­cio\n",
    "SC_TZ = ZoneInfo(\"America/Sao_Paulo\")\n",
    "inicio = datetime.now(SC_TZ)\n",
    "print(f\"â–¶ï¸ InÃ­cio em: {inicio:%Y-%m-%d %H:%M:%S} (FlorianÃ³polis | SC)\\n\")\n",
    "\n",
    "# Leitura do arquivo\n",
    "arquivo = Path(\"Portfolio_analitico_coerencia.xlsx\")\n",
    "if not arquivo.exists():\n",
    "    sys.exit(f\"â›” Arquivo nÃ£o encontrado: {arquivo}\")\n",
    "df = pd.read_excel(arquivo)\n",
    "\n",
    "# PreparaÃ§Ã£o dos dados\n",
    "print(\"ğŸ“Š Preparando dados...\")\n",
    "df = df[['Cited by', 'ClassificaÃ§Ã£o de CoerÃªncia', 'Best Quartile', 'Year']]\n",
    "df['Best Quartile'] = df['Best Quartile'].fillna('NE').replace(['-', 'NÃ£o Encontrado'], 'NE')\n",
    "df['ClassificaÃ§Ã£o de CoerÃªncia'] = df['ClassificaÃ§Ã£o de CoerÃªncia'].fillna('MÃ©dia')\n",
    "df['Year'] = df['Year'].fillna(df['Year'].median())\n",
    "df['Cited by'] = df['Cited by'].fillna(0).astype(int)\n",
    "\n",
    "# Tratamento de valores extremos em Cited by (winsorizaÃ§Ã£o no top 5%)\n",
    "print(\"ğŸ” Tratando valores extremos em Cited by...\")\n",
    "cited_by_winsorized = stats.mstats.winsorize(df['Cited by'], limits=[0, 0.05])\n",
    "df['Cited by'] = cited_by_winsorized\n",
    "df['Log_Cited_by'] = np.log1p(df['Cited by'])\n",
    "\n",
    "# VerificaÃ§Ã£o de dados\n",
    "print(\"ğŸ” Verificando dados...\")\n",
    "print(f\"  â€¢ ObservaÃ§Ãµes: {len(df)}\")\n",
    "print(f\"  â€¢ Zeros em Cited by: {100 * (df['Cited by'] == 0).mean():.1f}%\")\n",
    "print(f\"  â€¢ Categorias em ClassificaÃ§Ã£o de CoerÃªncia: {df['ClassificaÃ§Ã£o de CoerÃªncia'].value_counts().to_dict()}\")\n",
    "print(f\"  â€¢ Categorias em Best Quartile: {df['Best Quartile'].value_counts().to_dict()}\")\n",
    "for col in ['Best Quartile', 'ClassificaÃ§Ã£o de CoerÃªncia']:\n",
    "    rare_cats = df[col].value_counts()[df[col].value_counts() < 100].index\n",
    "    if len(rare_cats) > 0:\n",
    "        print(f\"  â€¢ Aviso: Categorias raras em {col} (<100 observaÃ§Ãµes): {list(rare_cats)}\")\n",
    "\n",
    "# RegressÃ£o OLS (modelo principal)\n",
    "print(\"ğŸ“Š Rodando regressÃ£o OLS (H3a/b)...\")\n",
    "formula_ols = 'Q(\"Log_Cited_by\") ~ C(Q(\"ClassificaÃ§Ã£o de CoerÃªncia\")) + C(Q(\"Best Quartile\")) + Q(\"Year\")'\n",
    "modelo_ols = smf.ols(formula=formula_ols, data=df).fit(cov_type='HC3')\n",
    "\n",
    "# Tabela de resultados (apenas OLS)\n",
    "print(\"\\nğŸ“‹ Tabela de regressÃ£o OLS (H3a/b):\")\n",
    "tabela_ols = modelo_ols.summary2().tables[1].reset_index()\n",
    "tabela_ols['VariÃ¡vel'] = tabela_ols['index'].apply(limpar_nome_variavel_com_descricao)\n",
    "print(\"ğŸ” Colunas em tabela_ols:\", tabela_ols.columns.tolist())\n",
    "p_value_col_ols = 'P>|t|' if 'P>|t|' in tabela_ols.columns else 'P>|z|' if 'P>|z|' in tabela_ols.columns else 'pvalue'\n",
    "stat_col_ols = 't' if 't' in tabela_ols.columns else 'z'\n",
    "tabela_ols['Sig'] = tabela_ols[p_value_col_ols].apply(marcar_sig)\n",
    "\n",
    "# Adicionar a categoria de referÃªncia (Alta)\n",
    "alta_row = pd.DataFrame({\n",
    "    'index': ['C(Q(\"ClassificaÃ§Ã£o de CoerÃªncia\"))[T.Alta]'],\n",
    "    'Coef.': [0.0],\n",
    "    'Std.Err.': [0.0],\n",
    "    stat_col_ols: [0.0],\n",
    "    p_value_col_ols: [1.0],\n",
    "    'Sig': [''],\n",
    "    '[0.025': [0.0],\n",
    "    '0.975]': [0.0],\n",
    "    'VariÃ¡vel': ['Alta (coerÃªncia â‰¥ 0,80)']\n",
    "})\n",
    "tabela_ols = pd.concat([alta_row, tabela_ols], ignore_index=True)\n",
    "\n",
    "# Identificar se Ã© variÃ¡vel de controle\n",
    "tabela_ols[['Ordem', 'Ã‰ Controle']] = tabela_ols['VariÃ¡vel'].apply(lambda x: pd.Series(extrair_ordem_variavel(x)))\n",
    "\n",
    "# Separar variÃ¡veis independentes e de controle\n",
    "tabela_independentes = tabela_ols[tabela_ols['Ã‰ Controle'] == False].sort_values('Ordem')\n",
    "tabela_controle = tabela_ols[tabela_ols['Ã‰ Controle'] == True].sort_values('Ordem')\n",
    "\n",
    "# Concatenar as partes sem a linha divisÃ³ria com NaN\n",
    "tabela = pd.concat([tabela_independentes, tabela_controle], ignore_index=True)\n",
    "\n",
    "# Finalizar a tabela\n",
    "tabela = tabela[['VariÃ¡vel', 'Coef.', 'Std.Err.', stat_col_ols, p_value_col_ols, 'Sig', '[0.025', '0.975]']]\n",
    "tabela.columns = ['VariÃ¡vel', 'Coeficiente', 'Erro PadrÃ£o', 'z/t', 'p-valor', 'Sig', 'IC 95% inferior', 'IC 95% superior']\n",
    "tabela = tabela.round(4)\n",
    "tabela.to_excel(\"H3ab_Regressao_Comparativa_Resultados.xlsx\", index=False)\n",
    "\n",
    "# Imprimir a tabela no console\n",
    "print(\"Dependente: log(1 + Cited by) (OLS)\")\n",
    "print(tabela.to_string(index=False))\n",
    "\n",
    "# Resumo tÃ©cnico limpo\n",
    "print(\"\\nğŸ“Š Resumo tÃ©cnico do modelo:\\n\")\n",
    "resumo_ols = modelo_ols.summary().as_text()\n",
    "substituir_variaveis = {\n",
    "    r'C\\(Q\\(\"ClassificaÃ§Ã£o de CoerÃªncia\"\\)\\)\\[T\\.([^\\]]+)\\]': r'\\1',\n",
    "    r'Q\\(\"Year\"\\)': \"Ano\",\n",
    "    r'Intercept': 'Intercepto',\n",
    "    r'C\\(Q\\(\"Best Quartile\"\\)\\)\\[T\\.([^\\]]+)\\]': r'Quartil \\1'\n",
    "}\n",
    "resumo_ols_limpo = resumo_ols\n",
    "for padrao, nome_limpo in substituir_variaveis.items():\n",
    "    resumo_ols_limpo = re.sub(padrao, nome_limpo, resumo_ols_limpo)\n",
    "resumo_ols_limpo = re.sub(r'Dep\\. Variable:.*\\n', 'Dep. Variable: log(1 + Cited by)\\n', resumo_ols_limpo)\n",
    "resumo_combined = f\"Modelo OLS:\\n{resumo_ols_limpo}\\nSignificance levels: * p<0.05, ** p<0.01, *** p<0.001\"\n",
    "print(resumo_combined)\n",
    "\n",
    "# EstatÃ­sticas descritivas por ClassificaÃ§Ã£o de CoerÃªncia\n",
    "print(\"\\nğŸ“Š Gerando estatÃ­sticas por ClassificaÃ§Ã£o de CoerÃªncia...\")\n",
    "agg = df.groupby('ClassificaÃ§Ã£o de CoerÃªncia')['Cited by'].agg(['count', 'mean', 'std', 'median', 'min', 'max']).round(3)\n",
    "agg.columns = ['N Artigos', 'MÃ©dia', 'Desvio PadrÃ£o', 'Mediana', 'MÃ­nimo', 'MÃ¡ximo']\n",
    "agg = agg.sort_values('MÃ©dia', ascending=False)\n",
    "agg.to_excel(\"H3ab_Resumo_Por_Coerencia.xlsx\")\n",
    "\n",
    "# RelatÃ³rio final\n",
    "fim = datetime.now(SC_TZ)\n",
    "dur = str(fim - inicio).split('.')[0]\n",
    "print(\"\\nğŸ“ Arquivos gerados:\")\n",
    "print(\"  â€¢ H3ab_Regressao_Comparativa_Resultados.xlsx\")\n",
    "print(\"  â€¢ H3ab_Resumo_Por_Coerencia.xlsx\")\n",
    "print(\"\\n===== RELATÃ“RIO FINAL =====\")\n",
    "print(f\"Tempo de execuÃ§Ã£o: {dur}\")\n",
    "print(f\"Finalizado em: {fim:%Y-%m-%d %H:%M:%S} (FlorianÃ³polis | SC)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da57d7ed-a728-41a2-ab07-237489be56ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
